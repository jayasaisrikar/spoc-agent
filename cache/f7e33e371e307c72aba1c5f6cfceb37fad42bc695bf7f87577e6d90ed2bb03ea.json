{
  "prompt": "\nBased on the previously analyzed repository 'modelcontextprotocol-servers', please answer this question:\n\n## Previous Conversation:\n\n**Assistant:** ## Analysis of the Provided Model Context Protocol (MCP) Server Repository\n\nThis repository contains multiple MCP server implementations, each residing in its own subdirectory within the `src` folder.  The structure suggests a modular design allowing for different server types (e.g., filesystem, Git, everything) and transport mechanisms (e.g., stdio, SSE).\n\n**1. Detailed Architecture Summary:**\n\nThe repository follows a microservice-like architecture.  Each server type (`everything`, `fetch`, `f...\n\n\n\n\n\n**Current Question:** can you build a similar server inside flockshop repo?\n\n**COMPLETE FILE STRUCTURE AND CONTENTS:**\n\n**File Tree:**\n- .gitattributes\n- .github/pull_request_template.md\n- .github/workflows/python.yml\n- .github/workflows/release.yml\n- .github/workflows/typescript.yml\n- .gitignore\n- .vscode/settings.json\n- CODE_OF_CONDUCT.md\n- CONTRIBUTING.md\n- LICENSE\n- README.md\n- SECURITY.md\n- package-lock.json\n- package.json\n- scripts/release.py\n- src/everything/CLAUDE.md\n- src/everything/Dockerfile\n- src/everything/README.md\n- src/everything/everything.ts\n- src/everything/index.ts\n- src/everything/instructions.md\n- src/everything/package.json\n- src/everything/sse.ts\n- src/everything/stdio.ts\n- src/everything/streamableHttp.ts\n- src/everything/tsconfig.json\n- src/fetch/Dockerfile\n- src/fetch/LICENSE\n- src/fetch/README.md\n- src/fetch/pyproject.toml\n- src/fetch/src/mcp_server_fetch/__init__.py\n- src/fetch/src/mcp_server_fetch/__main__.py\n- src/fetch/src/mcp_server_fetch/server.py\n- src/filesystem/Dockerfile\n- src/filesystem/README.md\n- src/filesystem/__tests__/path-utils.test.ts\n- src/filesystem/__tests__/path-validation.test.ts\n- src/filesystem/__tests__/roots-utils.test.ts\n- src/filesystem/index.ts\n- src/filesystem/package.json\n- src/filesystem/path-utils.ts\n- src/filesystem/path-validation.ts\n- src/filesystem/roots-utils.ts\n- src/filesystem/tsconfig.json\n- src/git/.gitignore\n- src/git/Dockerfile\n- src/git/LICENSE\n- src/git/README.md\n- src/git/pyproject.toml\n- src/git/src/mcp_server_git/__init__.py\n- src/git/src/mcp_server_git/__main__.py\n- src/git/src/mcp_server_git/server.py\n- src/git/tests/test_server.py\n- src/memory/Dockerfile\n- src/memory/README.md\n- src/memory/index.ts\n- src/memory/package.json\n- src/memory/tsconfig.json\n- src/sequentialthinking/Dockerfile\n- src/sequentialthinking/README.md\n- src/sequentialthinking/index.ts\n- src/sequentialthinking/package.json\n- src/sequentialthinking/tsconfig.json\n- src/time/Dockerfile\n- src/time/README.md\n- src/time/pyproject.toml\n- src/time/src/mcp_server_time/__init__.py\n- src/time/src/mcp_server_time/__main__.py\n- src/time/src/mcp_server_time/server.py\n- src/time/test/time_server_test.py\n- tsconfig.json\n\n**File Contents:**\n\n--- .github/pull_request_template.md (md) ---\n<!-- Provide a brief description of your changes -->\n\n## Description\n\n## Server Details\n<!-- If modifying an existing server, provide details -->\n- Server: <!-- e.g., filesystem, github -->\n- Changes to: <!-- e.g., tools, resources, prompts -->\n\n## Motivation and Context\n<!-- Why is this change needed? What problem does it solve? -->\n\n## How Has This Been Tested?\n<!-- Have you tested this with an LLM client? Which scenarios were tested? -->\n\n## Breaking Changes\n<!-- Will users need to update their MCP client configurations? -->\n\n## Types of changes\n<!-- What types of changes does your code introduce? Put an `x` in all the boxes that apply: -->\n- [ ] Bug fix (non-breaking change which fixes an issue)\n- [ ] New feature (non-breaking change which adds functionality)\n- [ ] Breaking change (fix or feature that would cause existing functionality to change)\n- [ ] Documentation update\n\n## Checklist\n<!-- Go over all the following points, and put an `x` in all the boxes that apply. -->\n- [ ] I have read the [MCP Protocol Documentation](https://modelcontextprotocol.io)\n- [ ] My changes follows MCP security best practices\n- [ ] I have updated the server's README accordingly\n- [ ] I have tested this with an LLM client\n- [ ] My code follows the repository's style guidelines\n- [ ] New and existing tests pass locally\n- [ ] I have added appropriate error handling\n- [ ] I have documented all environment variables and configuration options\n\n## Additional context\n<!-- Add any other context, implementation notes, or design decisions -->\n\n\n--- .github/workflows/python.yml (yml) ---\nname: Python\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n  release:\n    types: [published]\n\njobs:\n  detect-packages:\n    runs-on: ubuntu-latest\n    outputs:\n      packages: ${{ steps.find-packages.outputs.packages }}\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Find Python packages\n        id: find-packages\n        working-directory: src\n        run: |\n          PACKAGES=$(find . -name pyproject.toml -exec dirname {} \\; | sed 's/^\\.\\///' | jq -R -s -c 'split(\"\\n\")[:-1]')\n          echo \"packages=$PACKAGES\" >> $GITHUB_OUTPUT\n\n  test:\n    needs: [detect-packages]\n    strategy:\n      matrix:\n        package: ${{ fromJson(needs.detect-packages.outputs.packages) }}\n    name: Test ${{ matrix.package }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version-file: \"src/${{ matrix.package }}/.python-version\"\n\n      - name: Install dependencies\n        working-directory: src/${{ matrix.package }}\n        run: uv sync --frozen --all-extras --dev\n\n      - name: Check if tests exist\n        id: check-tests\n        working-directory: src/${{ matrix.package }}\n        run: |\n          if [ -d \"tests\" ] || [ -d \"test\" ] || grep -q \"pytest\" pyproject.toml; then\n            echo \"has-tests=true\" >> $GITHUB_OUTPUT\n          else\n            echo \"has-tests=false\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Run tests\n        if: steps.check-tests.outputs.has-tests == 'true'\n        working-directory: src/${{ matrix.package }}\n        run: uv run pytest\n\n  build:\n    needs: [detect-packages, test]\n    strategy:\n      matrix:\n        package: ${{ fromJson(needs.detect-packages.outputs.packages) }}\n    name: Build ${{ matrix.package }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v3\n\n      - na\n... (content truncated)\n\n--- .github/workflows/release.yml (yml) ---\nname: Automatic Release Creation\n\non:\n  workflow_dispatch:\n  schedule:\n    - cron: '0 10 * * *'\n\njobs:\n  create-metadata:\n    runs-on: ubuntu-latest\n    outputs:\n      hash: ${{ steps.last-release.outputs.hash }}\n      version: ${{ steps.create-version.outputs.version}}\n      npm_packages: ${{ steps.create-npm-packages.outputs.npm_packages}}\n      pypi_packages: ${{ steps.create-pypi-packages.outputs.pypi_packages}}\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Get last release hash\n        id: last-release\n        run: |\n          HASH=$(git rev-list --tags --max-count=1 || echo \"HEAD~1\")\n          echo \"hash=${HASH}\" >> $GITHUB_OUTPUT\n          echo \"Using last release hash: ${HASH}\"\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v5\n\n      - name: Create version name\n        id: create-version\n        run: |\n          VERSION=$(uv run --script scripts/release.py generate-version)\n          echo \"version $VERSION\"\n          echo \"version=$VERSION\" >> $GITHUB_OUTPUT\n\n      - name: Create notes\n        run: |\n          HASH=\"${{ steps.last-release.outputs.hash }}\"\n          uv run --script scripts/release.py generate-notes --directory src/ $HASH > RELEASE_NOTES.md\n          cat RELEASE_NOTES.md\n\n      - name: Release notes\n        uses: actions/upload-artifact@v4\n        with:\n          name: release-notes\n          path: RELEASE_NOTES.md\n\n      - name: Create python matrix\n        id: create-pypi-packages\n        run: |\n          HASH=\"${{ steps.last-release.outputs.hash }}\"\n          PYPI=$(uv run --script scripts/release.py generate-matrix --pypi --directory src $HASH)\n          echo \"pypi_packages $PYPI\"\n          echo \"pypi_packages=$PYPI\" >> $GITHUB_OUTPUT\n\n      - name: Create npm matrix\n        id: create-npm-packages\n        run: |\n          HASH=\"${{ steps.last-release.outputs.hash }}\"\n          NPM=$(uv run --script scripts/release.py generate-matrix --npm --directory src $HASH)\n          ech\n... (content truncated)\n\n--- .github/workflows/typescript.yml (yml) ---\nname: TypeScript\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n  release:\n    types: [published]\n\njobs:\n  detect-packages:\n    runs-on: ubuntu-latest\n    outputs:\n      packages: ${{ steps.find-packages.outputs.packages }}\n    steps:\n      - uses: actions/checkout@v4\n      - name: Find JS packages\n        id: find-packages\n        working-directory: src\n        run: |\n          PACKAGES=$(find . -name package.json -not -path \"*/node_modules/*\" -exec dirname {} \\; | sed 's/^\\.\\///' | jq -R -s -c 'split(\"\\n\")[:-1]')\n          echo \"packages=$PACKAGES\" >> $GITHUB_OUTPUT\n\n  test:\n    needs: [detect-packages]\n    strategy:\n      matrix:\n        package: ${{ fromJson(needs.detect-packages.outputs.packages) }}\n    name: Test ${{ matrix.package }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: npm\n\n      - name: Install dependencies\n        working-directory: src/${{ matrix.package }}\n        run: npm ci\n\n      - name: Check if tests exist\n        id: check-tests\n        working-directory: src/${{ matrix.package }}\n        run: |\n          if npm run test --silent 2>/dev/null; then\n            echo \"has-tests=true\" >> $GITHUB_OUTPUT\n          else\n            echo \"has-tests=false\" >> $GITHUB_OUTPUT\n          fi\n        continue-on-error: true\n\n      - name: Run tests\n        if: steps.check-tests.outputs.has-tests == 'true'\n        working-directory: src/${{ matrix.package }}\n        run: npm test\n\n  build:\n    needs: [detect-packages, test]\n    strategy:\n      matrix:\n        package: ${{ fromJson(needs.detect-packages.outputs.packages) }}\n    name: Build ${{ matrix.package }}\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 22\n          cache: npm\n\n      - name: Install dependencies\n        working-directory: src/${{ matrix.package }}\n        run:\n... (content truncated)\n\n--- .vscode/settings.json (json) ---\n{}\n\n--- CODE_OF_CONDUCT.md (md) ---\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Con\n... (content truncated)\n\n--- CONTRIBUTING.md (md) ---\n# Contributing to MCP Servers\n\nThank you for your interest in contributing to the Model Context Protocol (MCP) servers! This document provides guidelines and instructions for contributing.\n\n## Types of Contributions\n\n### 1. New Servers\n\nThe repository contains reference implementations, as well as a list of community servers.\nWe generally don't accept new servers into the repository. We do accept pull requests to the [README.md](./README.md)\nadding a reference to your servers.\n\nPlease keep lists in alphabetical order to minimize merge conflicts when adding new items.\n\n- Check the [modelcontextprotocol.io](https://modelcontextprotocol.io) documentation\n- Ensure your server doesn't duplicate existing functionality\n- Consider whether your server would be generally useful to others\n- Follow [security best practices](https://modelcontextprotocol.io/docs/concepts/transports#security-considerations) from the MCP documentation\n- Create a PR adding a link to your server to the [README.md](./README.md).\n\n### 2. Improvements to Existing Servers\nEnhancements to existing servers are welcome! This includes:\n\n- Bug fixes\n- Performance improvements\n- New features\n- Security enhancements\n\n### 3. Documentation\nDocumentation improvements are always welcome:\n\n- Fixing typos or unclear instructions\n- Adding examples\n- Improving setup instructions\n- Adding troubleshooting guides\n\n## Getting Started\n\n1. Fork the repository\n2. Clone your fork:\n   ```bash\n   git clone https://github.com/your-username/servers.git\n   ```\n3. Add the upstream remote:\n   ```bash\n   git remote add upstream https://github.com/modelcontextprotocol/servers.git\n   ```\n4. Create a branch:\n   ```bash\n   git checkout -b my-feature\n   ```\n\n## Development Guidelines\n\n### Code Style\n- Follow the existing code style in the repository\n- Include appropriate type definitions\n- Add comments for complex logic\n\n### Documentation\n- Include a detailed README.md in your server directory\n- Document all configuration options\n- Provide\n... (content truncated)\n\n--- LICENSE (unknown) ---\nMIT License\n\nCopyright (c) 2024 Anthropic, PBC\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n\n\n--- README.md (md) ---\n# Model Context Protocol servers\n\nThis repository is a collection of *reference implementations* for the [Model Context Protocol](https://modelcontextprotocol.io/) (MCP), as well as references\nto community built servers and additional resources.\n\nThe servers in this repository showcase the versatility and extensibility of MCP, demonstrating how it can be used to give Large Language Models (LLMs) secure, controlled access to tools and data sources.\nTypically, each MCP server is implemented with an MCP SDK:\n- [C# MCP SDK](https://github.com/modelcontextprotocol/csharp-sdk)\n- [Go MCP SDK](https://github.com/modelcontextprotocol/go-sdk)\n- [Java MCP SDK](https://github.com/modelcontextprotocol/java-sdk)\n- [Kotlin MCP SDK](https://github.com/modelcontextprotocol/kotlin-sdk)\n- [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\n- [Typescript MCP SDK](https://github.com/modelcontextprotocol/typescript-sdk)\n\n> Note: Lists in this README are maintained in alphabetical order to minimize merge conflicts when adding new items.\n\n## 🌟 Reference Servers\n\nThese servers aim to demonstrate MCP features and the official SDKs.\n\n- **[Everything](src/everything)** - Reference / test server with prompts, resources, and tools\n- **[Fetch](src/fetch)** - Web content fetching and conversion for efficient LLM usage\n- **[Filesystem](src/filesystem)** - Secure file operations with configurable access controls\n- **[Git](src/git)** - Tools to read, search, and manipulate Git repositories\n- **[Memory](src/memory)** - Knowledge graph-based persistent memory system\n- **[Sequential Thinking](src/sequentialthinking)** - Dynamic and reflective problem-solving through thought sequences\n- **[Time](src/time)** - Time and timezone conversion capabilities\n\n### Archived\n\nThe following reference servers are now archived and can be found at [servers-archived](https://github.com/modelcontextprotocol/servers-archived).\n\n- **[AWS KB Retrieval](https://github.com/modelcontextprotocol/servers-archive\n... (content truncated)\n\n--- SECURITY.md (md) ---\n# Security Policy\nThank you for helping us keep our MCP servers secure.\n\nThe **reference servers** in this repo are maintained by [Anthropic](https://www.anthropic.com/) as part of the Model Context Protocol project.\n\nThe security of our systems and user data is Anthropic’s top priority. We appreciate the work of security researchers acting in good faith in identifying and reporting potential vulnerabilities.\n\n## Vulnerability Disclosure Program\n\nOur Vulnerability Program guidelines are defined on our [HackerOne program page](https://hackerone.com/anthropic-vdp). We ask that any validated vulnerability in this functionality be reported through the [submission form](https://hackerone.com/anthropic-vdp/reports/new?type=team&report_type=vulnerability).\n\n\n--- package-lock.json (json) ---\n{\n  \"name\": \"@modelcontextprotocol/servers\",\n  \"version\": \"0.6.2\",\n  \"lockfileVersion\": 3,\n  \"requires\": true,\n  \"packages\": {\n    \"\": {\n      \"name\": \"@modelcontextprotocol/servers\",\n      \"version\": \"0.6.2\",\n      \"license\": \"MIT\",\n      \"workspaces\": [\n        \"src/*\"\n      ],\n      \"dependencies\": {\n        \"@modelcontextprotocol/server-everything\": \"*\",\n        \"@modelcontextprotocol/server-filesystem\": \"*\",\n        \"@modelcontextprotocol/server-memory\": \"*\",\n        \"@modelcontextprotocol/server-sequential-thinking\": \"*\"\n      }\n    },\n    \"node_modules/@ampproject/remapping\": {\n      \"version\": \"2.3.0\",\n      \"resolved\": \"https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz\",\n      \"integrity\": \"sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==\",\n      \"dev\": true,\n      \"license\": \"Apache-2.0\",\n      \"dependencies\": {\n        \"@jridgewell/gen-mapping\": \"^0.3.5\",\n        \"@jridgewell/trace-mapping\": \"^0.3.24\"\n      },\n      \"engines\": {\n        \"node\": \">=6.0.0\"\n      }\n    },\n    \"node_modules/@babel/code-frame\": {\n      \"version\": \"7.26.2\",\n      \"resolved\": \"https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.26.2.tgz\",\n      \"integrity\": \"sha512-RJlIHRueQgwWitWgF8OdFYGZX328Ax5BCemNGlqHfplnRT9ESi8JkFlvaVYbS+UubVY6dpv87Fs2u5M29iNFVQ==\",\n      \"dev\": true,\n      \"dependencies\": {\n        \"@babel/helper-validator-identifier\": \"^7.25.9\",\n        \"js-tokens\": \"^4.0.0\",\n        \"picocolors\": \"^1.0.0\"\n      },\n      \"engines\": {\n        \"node\": \">=6.9.0\"\n      }\n    },\n    \"node_modules/@babel/compat-data\": {\n      \"version\": \"7.26.8\",\n      \"resolved\": \"https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.26.8.tgz\",\n      \"integrity\": \"sha512-oH5UPLMWR3L2wEFLnFJ1TZXqHufiTKAiLfqw5zkhS4dKXLJ10yVztfil/twG8EDTA4F/tvVNw9nOl4ZMslB8rQ==\",\n      \"dev\": true,\n      \"license\": \"MIT\",\n      \"engines\": {\n        \"node\": \">=6.9.0\"\n      }\n    },\n    \"node_modules/@babel/core\": {\n      \"version\":\n... (content truncated)\n\n--- package.json (json) ---\n{\n  \"name\": \"@modelcontextprotocol/servers\",\n  \"private\": true,\n  \"version\": \"0.6.2\",\n  \"description\": \"Model Context Protocol servers\",\n  \"license\": \"MIT\",\n  \"author\": \"Anthropic, PBC (https://anthropic.com)\",\n  \"homepage\": \"https://modelcontextprotocol.io\",\n  \"bugs\": \"https://github.com/modelcontextprotocol/servers/issues\",\n  \"type\": \"module\",\n  \"workspaces\": [\n    \"src/*\"\n  ],\n  \"files\": [],\n  \"scripts\": {\n    \"build\": \"npm run build --workspaces\",\n    \"watch\": \"npm run watch --workspaces\",\n    \"publish-all\": \"npm publish --workspaces --access public\",\n    \"link-all\": \"npm link --workspaces\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/server-everything\": \"*\",\n    \"@modelcontextprotocol/server-memory\": \"*\",\n    \"@modelcontextprotocol/server-filesystem\": \"*\",\n    \"@modelcontextprotocol/server-sequential-thinking\": \"*\"\n  }\n}\n\n\n--- scripts/release.py (py) ---\n#!/usr/bin/env uv run --script\n# /// script\n# requires-python = \">=3.12\"\n# dependencies = [\n#     \"click>=8.1.8\",\n#     \"tomlkit>=0.13.2\"\n# ]\n# ///\nimport sys\nimport re\nimport click\nfrom pathlib import Path\nimport json\nimport tomlkit\nimport datetime\nimport subprocess\nfrom dataclasses import dataclass\nfrom typing import Any, Iterator, NewType, Protocol\n\n\nVersion = NewType(\"Version\", str)\nGitHash = NewType(\"GitHash\", str)\n\n\nclass GitHashParamType(click.ParamType):\n    name = \"git_hash\"\n\n    def convert(\n        self, value: Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> GitHash | None:\n        if value is None:\n            return None\n\n        if not (8 <= len(value) <= 40):\n            self.fail(f\"Git hash must be between 8 and 40 characters, got {len(value)}\")\n\n        if not re.match(r\"^[0-9a-fA-F]+$\", value):\n            self.fail(\"Git hash must contain only hex digits (0-9, a-f)\")\n\n        try:\n            # Verify hash exists in repo\n            subprocess.run(\n                [\"git\", \"rev-parse\", \"--verify\", value], check=True, capture_output=True\n            )\n        except subprocess.CalledProcessError:\n            self.fail(f\"Git hash {value} not found in repository\")\n\n        return GitHash(value.lower())\n\n\nGIT_HASH = GitHashParamType()\n\n\nclass Package(Protocol):\n    path: Path\n\n    def package_name(self) -> str: ...\n\n    def update_version(self, version: Version) -> None: ...\n\n\n@dataclass\nclass NpmPackage:\n    path: Path\n\n    def package_name(self) -> str:\n        with open(self.path / \"package.json\", \"r\") as f:\n            return json.load(f)[\"name\"]\n\n    def update_version(self, version: Version):\n        with open(self.path / \"package.json\", \"r+\") as f:\n            data = json.load(f)\n            data[\"version\"] = version\n            f.seek(0)\n            json.dump(data, f, indent=2)\n            f.truncate()\n\n\n@dataclass\nclass PyPiPackage:\n    path: Path\n\n    def package_name(self) -> str:\n        with open(self.path / \"pyprojec\n... (content truncated)\n\n--- src/everything/CLAUDE.md (md) ---\n# MCP \"Everything\" Server - Development Guidelines\n\n## Build, Test & Run Commands\n- Build: `npm run build` - Compiles TypeScript to JavaScript\n- Watch mode: `npm run watch` - Watches for changes and rebuilds automatically\n- Run server: `npm run start` - Starts the MCP server using stdio transport\n- Run SSE server: `npm run start:sse` - Starts the MCP server with SSE transport\n- Prepare release: `npm run prepare` - Builds the project for publishing\n\n## Code Style Guidelines\n- Use ES modules with `.js` extension in import paths\n- Strictly type all functions and variables with TypeScript\n- Follow zod schema patterns for tool input validation\n- Prefer async/await over callbacks and Promise chains\n- Place all imports at top of file, grouped by external then internal\n- Use descriptive variable names that clearly indicate purpose\n- Implement proper cleanup for timers and resources in server shutdown\n- Follow camelCase for variables/functions, PascalCase for types/classes, UPPER_CASE for constants\n- Handle errors with try/catch blocks and provide clear error messages\n- Use consistent indentation (2 spaces) and trailing commas in multi-line objects\n\n--- src/everything/Dockerfile (unknown) ---\nFROM node:22.12-alpine AS builder\n\nCOPY src/everything /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nCMD [\"node\", \"dist/index.js\"]\n\n--- src/everything/README.md (md) ---\n# Everything MCP Server\n\nThis MCP server attempts to exercise all the features of the MCP protocol. It is not intended to be a useful server, but rather a test server for builders of MCP clients. It implements prompts, tools, resources, sampling, and more to showcase MCP capabilities.\n\n## Components\n\n### Tools\n\n1. `echo`\n   - Simple tool to echo back input messages\n   - Input:\n     - `message` (string): Message to echo back\n   - Returns: Text content with echoed message\n\n2. `add`\n   - Adds two numbers together\n   - Inputs:\n     - `a` (number): First number\n     - `b` (number): Second number\n   - Returns: Text result of the addition\n\n3. `longRunningOperation`\n   - Demonstrates progress notifications for long operations\n   - Inputs:\n     - `duration` (number, default: 10): Duration in seconds\n     - `steps` (number, default: 5): Number of progress steps\n   - Returns: Completion message with duration and steps\n   - Sends progress notifications during execution\n\n4. `sampleLLM`\n   - Demonstrates LLM sampling capability using MCP sampling feature\n   - Inputs:\n     - `prompt` (string): The prompt to send to the LLM\n     - `maxTokens` (number, default: 100): Maximum tokens to generate\n   - Returns: Generated LLM response\n\n5. `getTinyImage`\n   - Returns a small test image\n   - No inputs required\n   - Returns: Base64 encoded PNG image data\n\n6. `printEnv`\n   - Prints all environment variables\n   - Useful for debugging MCP server configuration\n   - No inputs required\n   - Returns: JSON string of all environment variables\n\n7. `annotatedMessage`\n   - Demonstrates how annotations can be used to provide metadata about content\n   - Inputs:\n     - `messageType` (enum: \"error\" | \"success\" | \"debug\"): Type of message to demonstrate different annotation patterns\n     - `includeImage` (boolean, default: false): Whether to include an example image\n   - Returns: Content with varying annotations:\n     - Error messages: High priority (1.0), visible to both user and assistant\n     - Success m\n... (content truncated)\n\n--- src/everything/everything.ts (ts) ---\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport {\n  CallToolRequestSchema,\n  CompleteRequestSchema,\n  CreateMessageRequest,\n  CreateMessageResultSchema,\n  GetPromptRequestSchema,\n  ListPromptsRequestSchema,\n  ListResourcesRequestSchema,\n  ListResourceTemplatesRequestSchema,\n  ListToolsRequestSchema,\n  LoggingLevel,\n  ReadResourceRequestSchema,\n  Resource,\n  SetLevelRequestSchema,\n  SubscribeRequestSchema,\n  Tool,\n  ToolSchema,\n  UnsubscribeRequestSchema,\n} from \"@modelcontextprotocol/sdk/types.js\";\nimport { z } from \"zod\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\nimport { readFileSync } from \"fs\";\nimport { fileURLToPath } from \"url\";\nimport { dirname, join } from \"path\";\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = dirname(__filename);\nconst instructions = readFileSync(join(__dirname, \"instructions.md\"), \"utf-8\");\n\nconst ToolInputSchema = ToolSchema.shape.inputSchema;\ntype ToolInput = z.infer<typeof ToolInputSchema>;\n\n/* Input schemas for tools implemented in this server */\nconst EchoSchema = z.object({\n  message: z.string().describe(\"Message to echo\"),\n});\n\nconst AddSchema = z.object({\n  a: z.number().describe(\"First number\"),\n  b: z.number().describe(\"Second number\"),\n});\n\nconst LongRunningOperationSchema = z.object({\n  duration: z\n    .number()\n    .default(10)\n    .describe(\"Duration of the operation in seconds\"),\n  steps: z.number().default(5).describe(\"Number of steps in the operation\"),\n});\n\nconst PrintEnvSchema = z.object({});\n\nconst SampleLLMSchema = z.object({\n  prompt: z.string().describe(\"The prompt to send to the LLM\"),\n  maxTokens: z\n    .number()\n    .default(100)\n    .describe(\"Maximum number of tokens to generate\"),\n});\n\n// Example completion values\nconst EXAMPLE_COMPLETIONS = {\n  style: [\"casual\", \"formal\", \"technical\", \"friendly\"],\n  temperature: [\"0\", \"0.5\", \"0.7\", \"1.0\"],\n  resourceId: [\"1\", \"2\", \"3\", \"4\", \"5\"],\n};\n\nconst GetTinyImageSchema = z.object({});\n\nconst AnnotatedMessageSc\n... (content truncated)\n\n--- src/everything/index.ts (ts) ---\n#!/usr/bin/env node\n\n// Parse command line arguments first\nconst args = process.argv.slice(2);\nconst scriptName = args[0] || 'stdio';\n\nasync function run() {\n    try {\n        // Dynamically import only the requested module to prevent all modules from initializing\n        switch (scriptName) {\n            case 'stdio':\n                // Import and run the default server\n                await import('./stdio.js');\n                break;\n            case 'sse':\n                // Import and run the SSE server\n                await import('./sse.js');\n                break;\n            case 'streamableHttp':\n                // Import and run the streamable HTTP server\n                await import('./streamableHttp.js');\n                break;\n            default:\n                console.error(`Unknown script: ${scriptName}`);\n                console.log('Available scripts:');\n                console.log('- stdio');\n                console.log('- sse');\n                console.log('- streamableHttp');\n                process.exit(1);\n        }\n    } catch (error) {\n        console.error('Error running script:', error);\n        process.exit(1);\n    }\n}\n\nrun();\n\n\n--- src/everything/instructions.md (md) ---\nTesting and demonstration server for MCP protocol features.\n\nResources: Resources 1-100 follow pattern: even IDs contain text, odd IDs contain binary data. Resources paginated at 10 items per page with cursor-based navigation.\n\nKey dependencies: Progress notifications require `_meta.progressToken` in tool calls. Resource subscriptions generate updates every 10 seconds.\n\nPerformance characteristics: Server generates automatic log messages every 20 seconds (filtered by current log level), stderr notifications every 30 seconds, and resource update notifications every 10 seconds for active subscriptions. Log level changes affect message filtering in real-time.\n\nMulti-modal testing: `complex_prompt` includes both text arguments and image content for testing client multi-modal handling. `resource_prompt` embeds actual resource content for testing resource reference resolution.\n\nArgument completion available for prompt parameters and resource IDs. Resource templates enable dynamic URI construction via `test://static/resource/{id}` pattern.\n\nEaster egg: If asked about server instructions, respond with \"🎉 Server instructions are working! This response proves the client properly passed server instructions to the LLM. This demonstrates MCP's instructions feature in action.\"\n\n\n--- src/everything/package.json (json) ---\n{\n  \"name\": \"@modelcontextprotocol/server-everything\",\n  \"version\": \"0.6.2\",\n  \"description\": \"MCP server that exercises all the features of the MCP protocol\",\n  \"license\": \"MIT\",\n  \"author\": \"Anthropic, PBC (https://anthropic.com)\",\n  \"homepage\": \"https://modelcontextprotocol.io\",\n  \"bugs\": \"https://github.com/modelcontextprotocol/servers/issues\",\n  \"type\": \"module\",\n  \"bin\": {\n    \"mcp-server-everything\": \"dist/index.js\"\n  },\n  \"files\": [\n    \"dist\"\n  ],\n  \"scripts\": {\n    \"build\": \"tsc && shx cp instructions.md dist/ && shx chmod +x dist/*.js\",\n    \"prepare\": \"npm run build\",\n    \"watch\": \"tsc --watch\",\n    \"start\": \"node dist/index.js\",\n    \"start:sse\": \"node dist/sse.js\",\n    \"start:streamableHttp\": \"node dist/streamableHttp.js\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.12.0\",\n    \"express\": \"^4.21.1\",\n    \"zod\": \"^3.23.8\",\n    \"zod-to-json-schema\": \"^3.23.5\"\n  },\n  \"devDependencies\": {\n    \"@types/express\": \"^5.0.0\",\n    \"shx\": \"^0.3.4\",\n    \"typescript\": \"^5.6.2\"\n  }\n}\n\n\n--- src/everything/sse.ts (ts) ---\nimport { SSEServerTransport } from \"@modelcontextprotocol/sdk/server/sse.js\";\nimport express from \"express\";\nimport { createServer } from \"./everything.js\";\n\nconsole.error('Starting SSE server...');\n\nconst app = express();\n\nconst transports: Map<string, SSEServerTransport> = new Map<string, SSEServerTransport>();\n\napp.get(\"/sse\", async (req, res) => {\n  let transport: SSEServerTransport;\n  const { server, cleanup } = createServer();\n\n  if (req?.query?.sessionId) {\n    const sessionId = (req?.query?.sessionId as string);\n    transport = transports.get(sessionId) as SSEServerTransport;\n    console.error(\"Client Reconnecting? This shouldn't happen; when client has a sessionId, GET /sse should not be called again.\", transport.sessionId);\n  } else {\n    // Create and store transport for new session\n    transport = new SSEServerTransport(\"/message\", res);\n    transports.set(transport.sessionId, transport);\n\n    // Connect server to transport\n    await server.connect(transport);\n    console.error(\"Client Connected: \", transport.sessionId);\n\n    // Handle close of connection\n    server.onclose = async () => {\n      console.error(\"Client Disconnected: \", transport.sessionId);\n      transports.delete(transport.sessionId);\n      await cleanup();\n    };\n\n  }\n\n});\n\napp.post(\"/message\", async (req, res) => {\n  const sessionId = (req?.query?.sessionId as string);\n  const transport = transports.get(sessionId);\n  if (transport) {\n    console.error(\"Client Message from\", sessionId);\n    await transport.handlePostMessage(req, res);\n  } else {\n    console.error(`No transport found for sessionId ${sessionId}`)\n  }\n});\n\nconst PORT = process.env.PORT || 3001;\napp.listen(PORT, () => {\n  console.error(`Server is running on port ${PORT}`);\n});\n\n\n--- src/everything/stdio.ts (ts) ---\n#!/usr/bin/env node\n\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport { createServer } from \"./everything.js\";\n\nconsole.error('Starting default (STDIO) server...');\n\nasync function main() {\n  const transport = new StdioServerTransport();\n  const {server, cleanup} = createServer();\n\n  await server.connect(transport);\n\n  // Cleanup on exit\n  process.on(\"SIGINT\", async () => {\n    await cleanup();\n    await server.close();\n    process.exit(0);\n  });\n}\n\nmain().catch((error) => {\n  console.error(\"Server error:\", error);\n  process.exit(1);\n});\n\n\n\n--- src/everything/streamableHttp.ts (ts) ---\nimport { StreamableHTTPServerTransport } from \"@modelcontextprotocol/sdk/server/streamableHttp.js\";\nimport { InMemoryEventStore } from '@modelcontextprotocol/sdk/examples/shared/inMemoryEventStore.js';\nimport express, { Request, Response } from \"express\";\nimport { createServer } from \"./everything.js\";\nimport { randomUUID } from 'node:crypto';\n\nconsole.error('Starting Streamable HTTP server...');\n\nconst app = express();\n\nconst transports: Map<string, StreamableHTTPServerTransport> = new Map<string, StreamableHTTPServerTransport>();\n\napp.post('/mcp', async (req: Request, res: Response) => {\n  console.error('Received MCP POST request');\n  try {\n    // Check for existing session ID\n    const sessionId = req.headers['mcp-session-id'] as string | undefined;\n    let transport: StreamableHTTPServerTransport;\n\n    if (sessionId && transports.has(sessionId)) {\n      // Reuse existing transport\n      transport = transports.get(sessionId)!;\n    } else if (!sessionId) {\n\n      const { server, cleanup } = createServer();\n\n      // New initialization request\n      const eventStore = new InMemoryEventStore();\n      transport = new StreamableHTTPServerTransport({\n        sessionIdGenerator: () => randomUUID(),\n        eventStore, // Enable resumability\n        onsessioninitialized: (sessionId: string) => {\n          // Store the transport by session ID when session is initialized\n          // This avoids race conditions where requests might come in before the session is stored\n          console.error(`Session initialized with ID: ${sessionId}`);\n          transports.set(sessionId, transport);\n        }\n      });\n\n\n      // Set up onclose handler to clean up transport when closed\n      server.onclose = async () => {\n        const sid = transport.sessionId;\n        if (sid && transports.has(sid)) {\n          console.error(`Transport closed for session ${sid}, removing from transports map`);\n          transports.delete(sid);\n          await cleanup();\n        }\n      };\n\n      // Conn\n... (content truncated)\n\n--- src/everything/tsconfig.json (json) ---\n{\n  \"extends\": \"../../tsconfig.json\",\n  \"compilerOptions\": {\n    \"outDir\": \"./dist\",\n    \"rootDir\": \".\"\n  },\n  \"include\": [\n    \"./**/*.ts\"\n  ]\n}\n\n\n--- src/fetch/Dockerfile (unknown) ---\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-server-fetch\"]\n\n\n--- src/fetch/LICENSE (unknown) ---\nCopyright (c) 2024 Anthropic, PBC.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n--- src/fetch/README.md (md) ---\n# Fetch MCP Server\n\nA Model Context Protocol server that provides web content fetching capabilities. This server enables LLMs to retrieve and process content from web pages, converting HTML to markdown for easier consumption.\n\n> [!CAUTION]\n> This server can access local/internal IP addresses and may represent a security risk. Exercise caution when using this MCP server to ensure this does not expose any sensitive data.\n\nThe fetch tool will truncate the response, but by using the `start_index` argument, you can specify where to start the content extraction. This lets models read a webpage in chunks, until they find the information they need.\n\n### Available Tools\n\n- `fetch` - Fetches a URL from the internet and extracts its contents as markdown.\n    - `url` (string, required): URL to fetch\n    - `max_length` (integer, optional): Maximum number of characters to return (default: 5000)\n    - `start_index` (integer, optional): Start content from this character index (default: 0)\n    - `raw` (boolean, optional): Get raw content without markdown conversion (default: false)\n\n### Prompts\n\n- **fetch**\n  - Fetch a URL and extract its contents as markdown\n  - Arguments:\n    - `url` (string, required): URL to fetch\n\n## Installation\n\nOptionally: Install node.js, this will cause the fetch server to use a different HTML simplifier that is more robust.\n\n### Using uv (recommended)\n\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *mcp-server-fetch*.\n\n### Using PIP\n\nAlternatively you can install `mcp-server-fetch` via pip:\n\n```\npip install mcp-server-fetch\n```\n\nAfter installation, you can run it as a script using:\n\n```\npython -m mcp_server_fetch\n```\n\n## Configuration\n\n### Configure for Claude.app\n\nAdd to your Claude settings:\n\n<details>\n<summary>Using uvx</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"fetch\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-fetch\"]\n    }\n  }\n}\n... (content truncated)\n\n--- src/fetch/pyproject.toml (toml) ---\n[project]\nname = \"mcp-server-fetch\"\nversion = \"0.6.3\"\ndescription = \"A Model Context Protocol server providing tools to fetch and convert web content for usage by LLMs\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nauthors = [{ name = \"Anthropic, PBC.\" }]\nmaintainers = [{ name = \"Jack Adamson\", email = \"jadamson@anthropic.com\" }]\nkeywords = [\"http\", \"mcp\", \"llm\", \"automation\"]\nlicense = { text = \"MIT\" }\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n]\ndependencies = [\n    \"httpx<0.28\",\n    \"markdownify>=0.13.1\",\n    \"mcp>=1.1.3\",\n    \"protego>=0.3.1\",\n    \"pydantic>=2.0.0\",\n    \"readabilipy>=0.2.0\",\n    \"requests>=2.32.3\",\n]\n\n[project.scripts]\nmcp-server-fetch = \"mcp_server_fetch:main\"\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.uv]\ndev-dependencies = [\"pyright>=1.1.389\", \"ruff>=0.7.3\"]\n\n\n--- src/fetch/src/mcp_server_fetch/__init__.py (py) ---\nfrom .server import serve\n\n\ndef main():\n    \"\"\"MCP Fetch Server - HTTP fetching functionality for MCP\"\"\"\n    import argparse\n    import asyncio\n\n    parser = argparse.ArgumentParser(\n        description=\"give a model the ability to make web requests\"\n    )\n    parser.add_argument(\"--user-agent\", type=str, help=\"Custom User-Agent string\")\n    parser.add_argument(\n        \"--ignore-robots-txt\",\n        action=\"store_true\",\n        help=\"Ignore robots.txt restrictions\",\n    )\n    parser.add_argument(\"--proxy-url\", type=str, help=\"Proxy URL to use for requests\")\n\n    args = parser.parse_args()\n    asyncio.run(serve(args.user_agent, args.ignore_robots_txt, args.proxy_url))\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n--- src/fetch/src/mcp_server_fetch/__main__.py (py) ---\n# __main__.py\n\nfrom mcp_server_fetch import main\n\nmain()\n\n\n--- src/fetch/src/mcp_server_fetch/server.py (py) ---\nfrom typing import Annotated, Tuple\nfrom urllib.parse import urlparse, urlunparse\n\nimport markdownify\nimport readabilipy.simple_json\nfrom mcp.shared.exceptions import McpError\nfrom mcp.server import Server\nfrom mcp.server.stdio import stdio_server\nfrom mcp.types import (\n    ErrorData,\n    GetPromptResult,\n    Prompt,\n    PromptArgument,\n    PromptMessage,\n    TextContent,\n    Tool,\n    INVALID_PARAMS,\n    INTERNAL_ERROR,\n)\nfrom protego import Protego\nfrom pydantic import BaseModel, Field, AnyUrl\n\nDEFAULT_USER_AGENT_AUTONOMOUS = \"ModelContextProtocol/1.0 (Autonomous; +https://github.com/modelcontextprotocol/servers)\"\nDEFAULT_USER_AGENT_MANUAL = \"ModelContextProtocol/1.0 (User-Specified; +https://github.com/modelcontextprotocol/servers)\"\n\n\ndef extract_content_from_html(html: str) -> str:\n    \"\"\"Extract and convert HTML content to Markdown format.\n\n    Args:\n        html: Raw HTML content to process\n\n    Returns:\n        Simplified markdown version of the content\n    \"\"\"\n    ret = readabilipy.simple_json.simple_json_from_html_string(\n        html, use_readability=True\n    )\n    if not ret[\"content\"]:\n        return \"<error>Page failed to be simplified from HTML</error>\"\n    content = markdownify.markdownify(\n        ret[\"content\"],\n        heading_style=markdownify.ATX,\n    )\n    return content\n\n\ndef get_robots_txt_url(url: str) -> str:\n    \"\"\"Get the robots.txt URL for a given website URL.\n\n    Args:\n        url: Website URL to get robots.txt for\n\n    Returns:\n        URL of the robots.txt file\n    \"\"\"\n    # Parse the URL into components\n    parsed = urlparse(url)\n\n    # Reconstruct the base URL with just scheme, netloc, and /robots.txt path\n    robots_url = urlunparse((parsed.scheme, parsed.netloc, \"/robots.txt\", \"\", \"\", \"\"))\n\n    return robots_url\n\n\nasync def check_may_autonomously_fetch_url(url: str, user_agent: str, proxy_url: str | None = None) -> None:\n    \"\"\"\n    Check if the URL can be fetched by the user agent according to the robots.txt file.\n    Raises a M\n... (content truncated)\n\n--- src/filesystem/Dockerfile (unknown) ---\nFROM node:22.12-alpine AS builder\n\nWORKDIR /app\n\nCOPY src/filesystem /app\nCOPY tsconfig.json /tsconfig.json\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN --mount=type=cache,target=/root/.npm-production npm ci --ignore-scripts --omit-dev\n\n\nFROM node:22-alpine AS release\n\nWORKDIR /app\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"/app/dist/index.js\"]\n\n--- src/filesystem/README.md (md) ---\n# Filesystem MCP Server\n\nNode.js server implementing Model Context Protocol (MCP) for filesystem operations.\n\n## Features\n\n- Read/write files\n- Create/list/delete directories\n- Move files/directories\n- Search files\n- Get file metadata\n- Dynamic directory access control via [Roots](https://modelcontextprotocol.io/docs/concepts/roots)\n\n## Directory Access Control\n\nThe server uses a flexible directory access control system. Directories can be specified via command-line arguments or dynamically via [Roots](https://modelcontextprotocol.io/docs/concepts/roots).\n\n### Method 1: Command-line Arguments\nSpecify Allowed directories when starting the server:\n```bash\nmcp-server-filesystem /path/to/dir1 /path/to/dir2\n```\n\n### Method 2: MCP Roots (Recommended)\nMCP clients that support [Roots](https://modelcontextprotocol.io/docs/concepts/roots) can dynamically update the Allowed directories. \n\nRoots notified by Client to Server, completely replace any server-side Allowed directories when provided.\n\n**Important**: If server starts without command-line arguments AND client doesn't support roots protocol (or provides empty roots), the server will throw an error during initialization.\n\nThis is the recommended method, as this enables runtime directory updates via `roots/list_changed` notifications without server restart, providing a more flexible and modern integration experience.\n\n### How It Works\n\nThe server's directory access control follows this flow:\n\n1. **Server Startup**\n   - Server starts with directories from command-line arguments (if provided)\n   - If no arguments provided, server starts with empty allowed directories\n\n2. **Client Connection & Initialization**\n   - Client connects and sends `initialize` request with capabilities\n   - Server checks if client supports roots protocol (`capabilities.roots`)\n   \n3. **Roots Protocol Handling** (if client supports roots)\n   - **On initialization**: Server requests roots from client via `roots/list`\n   - Client responds with its conf\n... (content truncated)\n\n--- src/filesystem/__tests__/path-utils.test.ts (ts) ---\nimport { describe, it, expect } from '@jest/globals';\nimport { normalizePath, expandHome, convertToWindowsPath } from '../path-utils.js';\n\ndescribe('Path Utilities', () => {\n  describe('convertToWindowsPath', () => {\n    it('leaves Unix paths unchanged', () => {\n      expect(convertToWindowsPath('/usr/local/bin'))\n        .toBe('/usr/local/bin');\n      expect(convertToWindowsPath('/home/user/some path'))\n        .toBe('/home/user/some path');\n    });\n\n    it('converts WSL paths to Windows format', () => {\n      expect(convertToWindowsPath('/mnt/c/NS/MyKindleContent'))\n        .toBe('C:\\\\NS\\\\MyKindleContent');\n    });\n\n    it('converts Unix-style Windows paths to Windows format', () => {\n      expect(convertToWindowsPath('/c/NS/MyKindleContent'))\n        .toBe('C:\\\\NS\\\\MyKindleContent');\n    });\n\n    it('leaves Windows paths unchanged but ensures backslashes', () => {\n      expect(convertToWindowsPath('C:\\\\NS\\\\MyKindleContent'))\n        .toBe('C:\\\\NS\\\\MyKindleContent');\n      expect(convertToWindowsPath('C:/NS/MyKindleContent'))\n        .toBe('C:\\\\NS\\\\MyKindleContent');\n    });\n\n    it('handles Windows paths with spaces', () => {\n      expect(convertToWindowsPath('C:\\\\Program Files\\\\Some App'))\n        .toBe('C:\\\\Program Files\\\\Some App');\n      expect(convertToWindowsPath('C:/Program Files/Some App'))\n        .toBe('C:\\\\Program Files\\\\Some App');\n    });\n\n    it('handles uppercase and lowercase drive letters', () => {\n      expect(convertToWindowsPath('/mnt/d/some/path'))\n        .toBe('D:\\\\some\\\\path');\n      expect(convertToWindowsPath('/d/some/path'))\n        .toBe('D:\\\\some\\\\path');\n    });\n  });\n\n  describe('normalizePath', () => {\n    it('preserves Unix paths', () => {\n      expect(normalizePath('/usr/local/bin'))\n        .toBe('/usr/local/bin');\n      expect(normalizePath('/home/user/some path'))\n        .toBe('/home/user/some path');\n      expect(normalizePath('\"/usr/local/some app/\"'))\n        .toBe('/usr/local/some app');\n    });\n\n    it('removes surroundi\n... (content truncated)\n\n--- src/filesystem/__tests__/path-validation.test.ts (ts) ---\nimport { describe, it, expect, beforeEach, afterEach } from '@jest/globals';\nimport * as path from 'path';\nimport * as fs from 'fs/promises';\nimport * as os from 'os';\nimport { isPathWithinAllowedDirectories } from '../path-validation.js';\n\ndescribe('Path Validation', () => {\n  it('allows exact directory match', () => {\n    const allowed = ['/home/user/project'];\n    expect(isPathWithinAllowedDirectories('/home/user/project', allowed)).toBe(true);\n  });\n\n  it('allows subdirectories', () => {\n    const allowed = ['/home/user/project'];\n    expect(isPathWithinAllowedDirectories('/home/user/project/src', allowed)).toBe(true);\n    expect(isPathWithinAllowedDirectories('/home/user/project/src/index.js', allowed)).toBe(true);\n    expect(isPathWithinAllowedDirectories('/home/user/project/deeply/nested/file.txt', allowed)).toBe(true);\n  });\n\n  it('blocks similar directory names (prefix vulnerability)', () => {\n    const allowed = ['/home/user/project'];\n    expect(isPathWithinAllowedDirectories('/home/user/project2', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/home/user/project_backup', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/home/user/project-old', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/home/user/projectile', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/home/user/project.bak', allowed)).toBe(false);\n  });\n\n  it('blocks paths outside allowed directories', () => {\n    const allowed = ['/home/user/project'];\n    expect(isPathWithinAllowedDirectories('/home/user/other', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/etc/passwd', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/home/user', allowed)).toBe(false);\n    expect(isPathWithinAllowedDirectories('/', allowed)).toBe(false);\n  });\n\n  it('handles multiple allowed directories', () => {\n    const allowed = ['/home/user/project1', '/home/user/project2'];\n    expect(isPathWithinAllowedDirect\n... (content truncated)\n\n--- src/filesystem/__tests__/roots-utils.test.ts (ts) ---\nimport { describe, it, expect, beforeEach, afterEach } from '@jest/globals';\nimport { getValidRootDirectories } from '../roots-utils.js';\nimport { mkdtempSync, rmSync, mkdirSync, writeFileSync, realpathSync } from 'fs';\nimport { tmpdir } from 'os';\nimport { join } from 'path';\nimport type { Root } from '@modelcontextprotocol/sdk/types.js';\n\ndescribe('getValidRootDirectories', () => {\n  let testDir1: string;\n  let testDir2: string;\n  let testDir3: string;\n  let testFile: string;\n\n  beforeEach(() => {\n    // Create test directories\n    testDir1 = realpathSync(mkdtempSync(join(tmpdir(), 'mcp-roots-test1-')));\n    testDir2 = realpathSync(mkdtempSync(join(tmpdir(), 'mcp-roots-test2-')));\n    testDir3 = realpathSync(mkdtempSync(join(tmpdir(), 'mcp-roots-test3-')));\n\n    // Create a test file (not a directory)\n    testFile = join(testDir1, 'test-file.txt');\n    writeFileSync(testFile, 'test content');\n  });\n\n  afterEach(() => {\n    // Cleanup\n    rmSync(testDir1, { recursive: true, force: true });\n    rmSync(testDir2, { recursive: true, force: true });\n    rmSync(testDir3, { recursive: true, force: true });\n  });\n\n  describe('valid directory processing', () => {\n    it('should process all URI formats and edge cases', async () => {\n      const roots = [\n        { uri: `file://${testDir1}`, name: 'File URI' },\n        { uri: testDir2, name: 'Plain path' },\n        { uri: testDir3 } // Plain path without name property\n      ];\n\n      const result = await getValidRootDirectories(roots);\n\n      expect(result).toContain(testDir1);\n      expect(result).toContain(testDir2);\n      expect(result).toContain(testDir3);\n      expect(result).toHaveLength(3);\n    });\n\n    it('should normalize complex paths', async () => {\n      const subDir = join(testDir1, 'subdir');\n      mkdirSync(subDir);\n      \n      const roots = [\n        { uri: `file://${testDir1}/./subdir/../subdir`, name: 'Complex Path' }\n      ];\n\n      const result = await getValidRootDirectories(roots);\n\n      expect(result)\n... (content truncated)\n\n--- src/filesystem/index.ts (ts) ---\n#!/usr/bin/env node\n\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport {\n  CallToolRequestSchema,\n  ListToolsRequestSchema,\n  ToolSchema,\n  RootsListChangedNotificationSchema,\n  type Root,\n} from \"@modelcontextprotocol/sdk/types.js\";\nimport fs from \"fs/promises\";\nimport path from \"path\";\nimport os from 'os';\nimport { randomBytes } from 'crypto';\nimport { z } from \"zod\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\nimport { diffLines, createTwoFilesPatch } from 'diff';\nimport { minimatch } from 'minimatch';\nimport { isPathWithinAllowedDirectories } from './path-validation.js';\nimport { getValidRootDirectories } from './roots-utils.js';\n\n// Command line argument parsing\nconst args = process.argv.slice(2);\nif (args.length === 0) {\n  console.error(\"Usage: mcp-server-filesystem [allowed-directory] [additional-directories...]\");\n  console.error(\"Note: Allowed directories can be provided via:\");\n  console.error(\"  1. Command-line arguments (shown above)\");\n  console.error(\"  2. MCP roots protocol (if client supports it)\");\n  console.error(\"At least one directory must be provided by EITHER method for the server to operate.\");\n}\n\n// Normalize all paths consistently\nfunction normalizePath(p: string): string {\n  return path.normalize(p);\n}\n\nfunction expandHome(filepath: string): string {\n  if (filepath.startsWith('~/') || filepath === '~') {\n    return path.join(os.homedir(), filepath.slice(1));\n  }\n  return filepath;\n}\n\n// Store allowed directories in normalized and resolved form\nlet allowedDirectories = await Promise.all(\n  args.map(async (dir) => {\n    const expanded = expandHome(dir);\n    const absolute = path.resolve(expanded);\n    try {\n      // Resolve symlinks in allowed directories during startup\n      const resolved = await fs.realpath(absolute);\n      return normalizePath(resolved);\n    } catch (error) {\n      // If we can't resolve (doesn't exist), us\n... (content truncated)\n\n--- src/filesystem/package.json (json) ---\n{\n  \"name\": \"@modelcontextprotocol/server-filesystem\",\n  \"version\": \"0.6.2\",\n  \"description\": \"MCP server for filesystem access\",\n  \"license\": \"MIT\",\n  \"author\": \"Anthropic, PBC (https://anthropic.com)\",\n  \"homepage\": \"https://modelcontextprotocol.io\",\n  \"bugs\": \"https://github.com/modelcontextprotocol/servers/issues\",\n  \"type\": \"module\",\n  \"bin\": {\n    \"mcp-server-filesystem\": \"dist/index.js\"\n  },\n  \"files\": [\n    \"dist\"\n  ],\n  \"scripts\": {\n    \"build\": \"tsc && shx chmod +x dist/*.js\",\n    \"prepare\": \"npm run build\",\n    \"watch\": \"tsc --watch\",\n    \"test\": \"jest --config=jest.config.cjs --coverage\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.12.3\",\n    \"diff\": \"^5.1.0\",\n    \"glob\": \"^10.3.10\",\n    \"minimatch\": \"^10.0.1\",\n    \"zod-to-json-schema\": \"^3.23.5\"\n  },\n  \"devDependencies\": {\n    \"@jest/globals\": \"^29.7.0\",\n    \"@types/diff\": \"^5.0.9\",\n    \"@types/jest\": \"^29.5.14\",\n    \"@types/minimatch\": \"^5.1.2\",\n    \"@types/node\": \"^22\",\n    \"jest\": \"^29.7.0\",\n    \"shx\": \"^0.3.4\",\n    \"ts-jest\": \"^29.1.1\",\n    \"ts-node\": \"^10.9.2\",\n    \"typescript\": \"^5.8.2\"\n  }\n}\n\n--- src/filesystem/path-utils.ts (ts) ---\nimport path from \"path\";\nimport os from 'os';\n\n/**\n * Converts WSL or Unix-style Windows paths to Windows format\n * @param p The path to convert\n * @returns Converted Windows path\n */\nexport function convertToWindowsPath(p: string): string {\n  // Handle WSL paths (/mnt/c/...)\n  if (p.startsWith('/mnt/')) {\n    const driveLetter = p.charAt(5).toUpperCase();\n    const pathPart = p.slice(6).replace(/\\//g, '\\\\');\n    return `${driveLetter}:${pathPart}`;\n  }\n  \n  // Handle Unix-style Windows paths (/c/...)\n  if (p.match(/^\\/[a-zA-Z]\\//)) {\n    const driveLetter = p.charAt(1).toUpperCase();\n    const pathPart = p.slice(2).replace(/\\//g, '\\\\');\n    return `${driveLetter}:${pathPart}`;\n  }\n\n  // Handle standard Windows paths, ensuring backslashes\n  if (p.match(/^[a-zA-Z]:/)) {\n    return p.replace(/\\//g, '\\\\');\n  }\n\n  // Leave non-Windows paths unchanged\n  return p;\n}\n\n/**\n * Normalizes path by standardizing format while preserving OS-specific behavior\n * @param p The path to normalize\n * @returns Normalized path\n */\nexport function normalizePath(p: string): string {\n  // Remove any surrounding quotes and whitespace\n  p = p.trim().replace(/^[\"']|[\"']$/g, '');\n  \n  // Check if this is a Unix path (starts with / but not a Windows or WSL path)\n  const isUnixPath = p.startsWith('/') && \n                    !p.match(/^\\/mnt\\/[a-z]\\//i) && \n                    !p.match(/^\\/[a-zA-Z]\\//);\n  \n  if (isUnixPath) {\n    // For Unix paths, just normalize without converting to Windows format\n    // Replace double slashes with single slashes and remove trailing slashes\n    return p.replace(/\\/+/g, '/').replace(/\\/+$/, '');\n  }\n  \n  // Convert WSL or Unix-style Windows paths to Windows format\n  p = convertToWindowsPath(p);\n  \n  // Handle double backslashes, preserving leading UNC \\\\\n  if (p.startsWith('\\\\\\\\')) {\n    // For UNC paths, first normalize any excessive leading backslashes to exactly \\\\\n    // Then normalize double backslashes in the rest of the path\n    let uncPath = p;\n    // Re\n... (content truncated)\n\n--- src/filesystem/path-validation.ts (ts) ---\nimport path from 'path';\n\n/**\n * Checks if an absolute path is within any of the allowed directories.\n * \n * @param absolutePath - The absolute path to check (will be normalized)\n * @param allowedDirectories - Array of absolute allowed directory paths (will be normalized)\n * @returns true if the path is within an allowed directory, false otherwise\n * @throws Error if given relative paths after normalization\n */\nexport function isPathWithinAllowedDirectories(absolutePath: string, allowedDirectories: string[]): boolean {\n  // Type validation\n  if (typeof absolutePath !== 'string' || !Array.isArray(allowedDirectories)) {\n    return false;\n  }\n\n  // Reject empty inputs\n  if (!absolutePath || allowedDirectories.length === 0) {\n    return false;\n  }\n\n  // Reject null bytes (forbidden in paths)\n  if (absolutePath.includes('\\x00')) {\n    return false;\n  }\n\n  // Normalize the input path\n  let normalizedPath: string;\n  try {\n    normalizedPath = path.resolve(path.normalize(absolutePath));\n  } catch {\n    return false;\n  }\n\n  // Verify it's absolute after normalization\n  if (!path.isAbsolute(normalizedPath)) {\n    throw new Error('Path must be absolute after normalization');\n  }\n\n  // Check against each allowed directory\n  return allowedDirectories.some(dir => {\n    if (typeof dir !== 'string' || !dir) {\n      return false;\n    }\n\n    // Reject null bytes in allowed dirs\n    if (dir.includes('\\x00')) {\n      return false;\n    }\n\n    // Normalize the allowed directory\n    let normalizedDir: string;\n    try {\n      normalizedDir = path.resolve(path.normalize(dir));\n    } catch {\n      return false;\n    }\n\n    // Verify allowed directory is absolute after normalization\n    if (!path.isAbsolute(normalizedDir)) {\n      throw new Error('Allowed directories must be absolute paths after normalization');\n    }\n\n    // Check if normalizedPath is within normalizedDir\n    // Path is inside if it's the same or a subdirectory\n    if (normalizedPath === normalizedDir) {\n      return true;\n  \n... (content truncated)\n\n--- src/filesystem/roots-utils.ts (ts) ---\nimport { promises as fs, type Stats } from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { normalizePath } from './path-utils.js';\nimport type { Root } from '@modelcontextprotocol/sdk/types.js';\n\n/**\n * Converts a root URI to a normalized directory path with basic security validation.\n * @param rootUri - File URI (file://...) or plain directory path\n * @returns Promise resolving to validated path or null if invalid\n */\nasync function parseRootUri(rootUri: string): Promise<string | null> {\n  try {\n    const rawPath = rootUri.startsWith('file://') ? rootUri.slice(7) : rootUri;\n    const expandedPath = rawPath.startsWith('~/') || rawPath === '~' \n      ? path.join(os.homedir(), rawPath.slice(1)) \n      : rawPath;\n    const absolutePath = path.resolve(expandedPath);\n    const resolvedPath = await fs.realpath(absolutePath);\n    return normalizePath(resolvedPath);\n  } catch {\n    return null; // Path doesn't exist or other error\n  }\n}\n\n/**\n * Formats error message for directory validation failures.\n * @param dir - Directory path that failed validation\n * @param error - Error that occurred during validation\n * @param reason - Specific reason for failure\n * @returns Formatted error message\n */\nfunction formatDirectoryError(dir: string, error?: unknown, reason?: string): string {\n  if (reason) {\n    return `Skipping ${reason}: ${dir}`;\n  }\n  const message = error instanceof Error ? error.message : String(error);\n  return `Skipping invalid directory: ${dir} due to error: ${message}`;\n}\n\n/**\n * Resolves requested root directories from MCP root specifications.\n * \n * Converts root URI specifications (file:// URIs or plain paths) into normalized\n * directory paths, validating that each path exists and is a directory.\n * Includes symlink resolution for security.\n * \n * @param requestedRoots - Array of root specifications with URI and optional name\n * @returns Promise resolving to array of validated directory paths\n */\nexport async function getValidRootDirectories(\n  \n... (content truncated)\n\n--- src/filesystem/tsconfig.json (json) ---\n{\n  \"extends\": \"../../tsconfig.json\",\n  \"compilerOptions\": {\n    \"outDir\": \"./dist\",\n    \"rootDir\": \".\",\n    \"moduleResolution\": \"NodeNext\",\n    \"module\": \"NodeNext\"\n  },\n  \"include\": [\n    \"./**/*.ts\"\n  ]\n}\n\n\n--- src/git/Dockerfile (unknown) ---\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nRUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-server-git\"]\n\n\n--- src/git/LICENSE (unknown) ---\nCopyright (c) 2024 Anthropic, PBC.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n--- src/git/README.md (md) ---\n# mcp-server-git: A git MCP server\n\n## Overview\n\nA Model Context Protocol server for Git repository interaction and automation. This server provides tools to read, search, and manipulate Git repositories via Large Language Models.\n\nPlease note that mcp-server-git is currently in early development. The functionality and available tools are subject to change and expansion as we continue to develop and improve the server.\n\n### Tools\n\n1. `git_status`\n   - Shows the working tree status\n   - Input:\n     - `repo_path` (string): Path to Git repository\n   - Returns: Current status of working directory as text output\n\n2. `git_diff_unstaged`\n   - Shows changes in working directory not yet staged\n   - Inputs:\n     - `repo_path` (string): Path to Git repository\n     - `context_lines` (number, optional): Number of context lines to show (default: 3)\n   - Returns: Diff output of unstaged changes\n\n3. `git_diff_staged`\n   - Shows changes that are staged for commit\n   - Inputs:\n     - `repo_path` (string): Path to Git repository\n     - `context_lines` (number, optional): Number of context lines to show (default: 3)\n   - Returns: Diff output of staged changes\n\n4. `git_diff`\n   - Shows differences between branches or commits\n   - Inputs:\n     - `repo_path` (string): Path to Git repository\n     - `target` (string): Target branch or commit to compare with\n     - `context_lines` (number, optional): Number of context lines to show (default: 3)\n   - Returns: Diff output comparing current state with target\n\n5. `git_commit`\n   - Records changes to the repository\n   - Inputs:\n     - `repo_path` (string): Path to Git repository\n     - `message` (string): Commit message\n   - Returns: Confirmation with new commit hash\n\n6. `git_add`\n   - Adds file contents to the staging area\n   - Inputs:\n     - `repo_path` (string): Path to Git repository\n     - `files` (string[]): Array of file paths to stage\n   - Returns: Confirmation of staged files\n\n7. `git_reset`\n   - Unstages all staged changes\n   - Input:\n \n... (content truncated)\n\n--- src/git/pyproject.toml (toml) ---\n[project]\nname = \"mcp-server-git\"\nversion = \"0.6.2\"\ndescription = \"A Model Context Protocol server providing tools to read, search, and manipulate Git repositories programmatically via LLMs\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nauthors = [{ name = \"Anthropic, PBC.\" }]\nmaintainers = [{ name = \"David Soria Parra\", email = \"davidsp@anthropic.com\" }]\nkeywords = [\"git\", \"mcp\", \"llm\", \"automation\"]\nlicense = { text = \"MIT\" }\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n]\ndependencies = [\n    \"click>=8.1.7\",\n    \"gitpython>=3.1.43\",\n    \"mcp>=1.0.0\",\n    \"pydantic>=2.0.0\",\n]\n\n[project.scripts]\nmcp-server-git = \"mcp_server_git:main\"\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.uv]\ndev-dependencies = [\"pyright>=1.1.389\", \"ruff>=0.7.3\", \"pytest>=8.0.0\"]\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = \"test_*.py\"\npython_classes = \"Test*\"\npython_functions = \"test_*\"\n\n\n--- src/git/src/mcp_server_git/__init__.py (py) ---\nimport click\nfrom pathlib import Path\nimport logging\nimport sys\nfrom .server import serve\n\n@click.command()\n@click.option(\"--repository\", \"-r\", type=Path, help=\"Git repository path\")\n@click.option(\"-v\", \"--verbose\", count=True)\ndef main(repository: Path | None, verbose: bool) -> None:\n    \"\"\"MCP Git Server - Git functionality for MCP\"\"\"\n    import asyncio\n\n    logging_level = logging.WARN\n    if verbose == 1:\n        logging_level = logging.INFO\n    elif verbose >= 2:\n        logging_level = logging.DEBUG\n\n    logging.basicConfig(level=logging_level, stream=sys.stderr)\n    asyncio.run(serve(repository))\n\nif __name__ == \"__main__\":\n    main()\n\n\n--- src/git/src/mcp_server_git/__main__.py (py) ---\n# __main__.py\n\nfrom mcp_server_git import main\n\nmain()\n\n\n--- src/git/src/mcp_server_git/server.py (py) ---\nimport logging\nfrom pathlib import Path\nfrom typing import Sequence, Optional\nfrom mcp.server import Server\nfrom mcp.server.session import ServerSession\nfrom mcp.server.stdio import stdio_server\nfrom mcp.types import (\n    ClientCapabilities,\n    TextContent,\n    Tool,\n    ListRootsResult,\n    RootsCapability,\n)\nfrom enum import Enum\nimport git\nfrom pydantic import BaseModel, Field\n\n# Default number of context lines to show in diff output\nDEFAULT_CONTEXT_LINES = 3\n\nclass GitStatus(BaseModel):\n    repo_path: str\n\nclass GitDiffUnstaged(BaseModel):\n    repo_path: str\n    context_lines: int = DEFAULT_CONTEXT_LINES\n\nclass GitDiffStaged(BaseModel):\n    repo_path: str\n    context_lines: int = DEFAULT_CONTEXT_LINES\n\nclass GitDiff(BaseModel):\n    repo_path: str\n    target: str\n    context_lines: int = DEFAULT_CONTEXT_LINES\n\nclass GitCommit(BaseModel):\n    repo_path: str\n    message: str\n\nclass GitAdd(BaseModel):\n    repo_path: str\n    files: list[str]\n\nclass GitReset(BaseModel):\n    repo_path: str\n\nclass GitLog(BaseModel):\n    repo_path: str\n    max_count: int = 10\n\nclass GitCreateBranch(BaseModel):\n    repo_path: str\n    branch_name: str\n    base_branch: str | None = None\n\nclass GitCheckout(BaseModel):\n    repo_path: str\n    branch_name: str\n\nclass GitShow(BaseModel):\n    repo_path: str\n    revision: str\n\nclass GitInit(BaseModel):\n    repo_path: str\n\nclass GitBranch(BaseModel):\n    repo_path: str = Field(\n        ...,\n        description=\"The path to the Git repository.\",\n    )\n    branch_type: str = Field(\n        ...,\n        description=\"Whether to list local branches ('local'), remote branches ('remote') or all branches('all').\",\n    )\n    contains: Optional[str] = Field(\n        None,\n        description=\"The commit sha that branch should contain. Do not pass anything to this param if no commit sha is specified\",\n    )\n    not_contains: Optional[str] = Field(\n        None,\n        description=\"The commit sha that branch should NOT contain. Do not pass anything to this \n... (content truncated)\n\n--- src/git/tests/test_server.py (py) ---\nimport pytest\nfrom pathlib import Path\nimport git\nfrom mcp_server_git.server import git_checkout, git_branch\nimport shutil\n\n@pytest.fixture\ndef test_repository(tmp_path: Path):\n    repo_path = tmp_path / \"temp_test_repo\"\n    test_repo = git.Repo.init(repo_path)\n\n    Path(repo_path / \"test.txt\").write_text(\"test\")\n    test_repo.index.add([\"test.txt\"])\n    test_repo.index.commit(\"initial commit\")\n\n    yield test_repo\n\n    shutil.rmtree(repo_path)\n\ndef test_git_checkout_existing_branch(test_repository):\n    test_repository.git.branch(\"test-branch\")\n    result = git_checkout(test_repository, \"test-branch\")\n\n    assert \"Switched to branch 'test-branch'\" in result\n    assert test_repository.active_branch.name == \"test-branch\"\n\ndef test_git_checkout_nonexistent_branch(test_repository):\n\n    with pytest.raises(git.GitCommandError):\n        git_checkout(test_repository, \"nonexistent-branch\")\n\ndef test_git_branch_local(test_repository):\n    test_repository.git.branch(\"new-branch-local\")\n    result = git_branch(test_repository, \"local\")\n    assert \"new-branch-local\" in result\n\ndef test_git_branch_remote(test_repository):\n    # GitPython does not easily support creating remote branches without a remote.\n    # This test will check the behavior when 'remote' is specified without actual remotes.\n    result = git_branch(test_repository, \"remote\")\n    assert \"\" == result.strip()  # Should be empty if no remote branches\n\ndef test_git_branch_all(test_repository):\n    test_repository.git.branch(\"new-branch-all\")\n    result = git_branch(test_repository, \"all\")\n    assert \"new-branch-all\" in result\n\ndef test_git_branch_contains(test_repository):\n    # Create a new branch and commit to it\n    test_repository.git.checkout(\"-b\", \"feature-branch\")\n    Path(test_repository.working_dir / Path(\"feature.txt\")).write_text(\"feature content\")\n    test_repository.index.add([\"feature.txt\"])\n    commit = test_repository.index.commit(\"feature commit\")\n    test_repository.git.checkout(\"master\")\n\n    res\n... (content truncated)\n\n--- src/memory/Dockerfile (unknown) ---\nFROM node:22.12-alpine AS builder\n\nCOPY src/memory /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN --mount=type=cache,target=/root/.npm-production npm ci --ignore-scripts --omit-dev\n\nFROM node:22-alpine AS release\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nWORKDIR /app\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]\n\n--- src/memory/README.md (md) ---\n# Knowledge Graph Memory Server\n\nA basic implementation of persistent memory using a local knowledge graph. This lets Claude remember information about the user across chats.\n\n## Core Concepts\n\n### Entities\nEntities are the primary nodes in the knowledge graph. Each entity has:\n- A unique name (identifier)\n- An entity type (e.g., \"person\", \"organization\", \"event\")\n- A list of observations\n\nExample:\n```json\n{\n  \"name\": \"John_Smith\",\n  \"entityType\": \"person\",\n  \"observations\": [\"Speaks fluent Spanish\"]\n}\n```\n\n### Relations\nRelations define directed connections between entities. They are always stored in active voice and describe how entities interact or relate to each other.\n\nExample:\n```json\n{\n  \"from\": \"John_Smith\",\n  \"to\": \"Anthropic\",\n  \"relationType\": \"works_at\"\n}\n```\n### Observations\nObservations are discrete pieces of information about an entity. They are:\n\n- Stored as strings\n- Attached to specific entities\n- Can be added or removed independently\n- Should be atomic (one fact per observation)\n\nExample:\n```json\n{\n  \"entityName\": \"John_Smith\",\n  \"observations\": [\n    \"Speaks fluent Spanish\",\n    \"Graduated in 2019\",\n    \"Prefers morning meetings\"\n  ]\n}\n```\n\n## API\n\n### Tools\n- **create_entities**\n  - Create multiple new entities in the knowledge graph\n  - Input: `entities` (array of objects)\n    - Each object contains:\n      - `name` (string): Entity identifier\n      - `entityType` (string): Type classification\n      - `observations` (string[]): Associated observations\n  - Ignores entities with existing names\n\n- **create_relations**\n  - Create multiple new relations between entities\n  - Input: `relations` (array of objects)\n    - Each object contains:\n      - `from` (string): Source entity name\n      - `to` (string): Target entity name\n      - `relationType` (string): Relationship type in active voice\n  - Skips duplicate relations\n\n- **add_observations**\n  - Add new observations to existing entities\n  - Input: `observations` (array of objects)\n    - Each object c\n... (content truncated)\n\n--- src/memory/index.ts (ts) ---\n#!/usr/bin/env node\n\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport {\n  CallToolRequestSchema,\n  ListToolsRequestSchema,\n} from \"@modelcontextprotocol/sdk/types.js\";\nimport { promises as fs } from 'fs';\nimport path from 'path';\nimport { fileURLToPath } from 'url';\n\n// Define memory file path using environment variable with fallback\nconst defaultMemoryPath = path.join(path.dirname(fileURLToPath(import.meta.url)), 'memory.json');\n\n// If MEMORY_FILE_PATH is just a filename, put it in the same directory as the script\nconst MEMORY_FILE_PATH = process.env.MEMORY_FILE_PATH\n  ? path.isAbsolute(process.env.MEMORY_FILE_PATH)\n    ? process.env.MEMORY_FILE_PATH\n    : path.join(path.dirname(fileURLToPath(import.meta.url)), process.env.MEMORY_FILE_PATH)\n  : defaultMemoryPath;\n\n// We are storing our memory using entities, relations, and observations in a graph structure\ninterface Entity {\n  name: string;\n  entityType: string;\n  observations: string[];\n}\n\ninterface Relation {\n  from: string;\n  to: string;\n  relationType: string;\n}\n\ninterface KnowledgeGraph {\n  entities: Entity[];\n  relations: Relation[];\n}\n\n// The KnowledgeGraphManager class contains all operations to interact with the knowledge graph\nclass KnowledgeGraphManager {\n  private async loadGraph(): Promise<KnowledgeGraph> {\n    try {\n      const data = await fs.readFile(MEMORY_FILE_PATH, \"utf-8\");\n      const lines = data.split(\"\\n\").filter(line => line.trim() !== \"\");\n      return lines.reduce((graph: KnowledgeGraph, line) => {\n        const item = JSON.parse(line);\n        if (item.type === \"entity\") graph.entities.push(item as Entity);\n        if (item.type === \"relation\") graph.relations.push(item as Relation);\n        return graph;\n      }, { entities: [], relations: [] });\n    } catch (error) {\n      if (error instanceof Error && 'code' in error && (error as any).code === \"ENOENT\") {\n        return { entiti\n... (content truncated)\n\n--- src/memory/package.json (json) ---\n{\n  \"name\": \"@modelcontextprotocol/server-memory\",\n  \"version\": \"0.6.3\",\n  \"description\": \"MCP server for enabling memory for Claude through a knowledge graph\",\n  \"license\": \"MIT\",\n  \"author\": \"Anthropic, PBC (https://anthropic.com)\",\n  \"homepage\": \"https://modelcontextprotocol.io\",\n  \"bugs\": \"https://github.com/modelcontextprotocol/servers/issues\",\n  \"type\": \"module\",\n  \"bin\": {\n    \"mcp-server-memory\": \"dist/index.js\"\n  },\n  \"files\": [\n    \"dist\"\n  ],\n  \"scripts\": {\n    \"build\": \"tsc && shx chmod +x dist/*.js\",\n    \"prepare\": \"npm run build\",\n    \"watch\": \"tsc --watch\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"1.0.1\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^22\",\n    \"shx\": \"^0.3.4\",\n    \"typescript\": \"^5.6.2\"\n  }\n}\n\n--- src/memory/tsconfig.json (json) ---\n{\n    \"extends\": \"../../tsconfig.json\",\n    \"compilerOptions\": {\n      \"outDir\": \"./dist\",\n      \"rootDir\": \".\"\n    },\n    \"include\": [\n      \"./**/*.ts\"\n    ]\n  }\n  \n\n--- src/sequentialthinking/Dockerfile (unknown) ---\nFROM node:22.12-alpine AS builder\n\nCOPY src/sequentialthinking /app\nCOPY tsconfig.json /tsconfig.json\n\nWORKDIR /app\n\nRUN --mount=type=cache,target=/root/.npm npm install\n\nRUN --mount=type=cache,target=/root/.npm-production npm ci --ignore-scripts --omit-dev\n\nFROM node:22-alpine AS release\n\nCOPY --from=builder /app/dist /app/dist\nCOPY --from=builder /app/package.json /app/package.json\nCOPY --from=builder /app/package-lock.json /app/package-lock.json\n\nENV NODE_ENV=production\n\nWORKDIR /app\n\nRUN npm ci --ignore-scripts --omit-dev\n\nENTRYPOINT [\"node\", \"dist/index.js\"]\n\n\n--- src/sequentialthinking/README.md (md) ---\n# Sequential Thinking MCP Server\n\nAn MCP server implementation that provides a tool for dynamic and reflective problem-solving through a structured thinking process.\n\n## Features\n\n- Break down complex problems into manageable steps\n- Revise and refine thoughts as understanding deepens\n- Branch into alternative paths of reasoning\n- Adjust the total number of thoughts dynamically\n- Generate and verify solution hypotheses\n\n## Tool\n\n### sequential_thinking\n\nFacilitates a detailed, step-by-step thinking process for problem-solving and analysis.\n\n**Inputs:**\n- `thought` (string): The current thinking step\n- `nextThoughtNeeded` (boolean): Whether another thought step is needed\n- `thoughtNumber` (integer): Current thought number\n- `totalThoughts` (integer): Estimated total thoughts needed\n- `isRevision` (boolean, optional): Whether this revises previous thinking\n- `revisesThought` (integer, optional): Which thought is being reconsidered\n- `branchFromThought` (integer, optional): Branching point thought number\n- `branchId` (string, optional): Branch identifier\n- `needsMoreThoughts` (boolean, optional): If more thoughts are needed\n\n## Usage\n\nThe Sequential Thinking tool is designed for:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\n## Configuration\n\n### Usage with Claude Desktop\n\nAdd this to your `claude_desktop_config.json`:\n\n#### npx\n\n```json\n{\n  \"mcpServers\": {\n    \"sequential-thinking\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"@modelcontextprotocol/server-sequential-thinking\"\n      ]\n    }\n  }\n}\n```\n\n#### docker\n\n```json\n{\n  \"mcpServers\": {\n    \"sequentialthinking\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"-i\",\n        \"mcp/sequentialt\n... (content truncated)\n\n--- src/sequentialthinking/index.ts (ts) ---\n#!/usr/bin/env node\n\nimport { Server } from \"@modelcontextprotocol/sdk/server/index.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport {\n  CallToolRequestSchema,\n  ListToolsRequestSchema,\n  Tool,\n} from \"@modelcontextprotocol/sdk/types.js\";\n// Fixed chalk import for ESM\nimport chalk from 'chalk';\n\ninterface ThoughtData {\n  thought: string;\n  thoughtNumber: number;\n  totalThoughts: number;\n  isRevision?: boolean;\n  revisesThought?: number;\n  branchFromThought?: number;\n  branchId?: string;\n  needsMoreThoughts?: boolean;\n  nextThoughtNeeded: boolean;\n}\n\nclass SequentialThinkingServer {\n  private thoughtHistory: ThoughtData[] = [];\n  private branches: Record<string, ThoughtData[]> = {};\n  private disableThoughtLogging: boolean;\n\n  constructor() {\n    this.disableThoughtLogging = (process.env.DISABLE_THOUGHT_LOGGING || \"\").toLowerCase() === \"true\";\n  }\n\n  private validateThoughtData(input: unknown): ThoughtData {\n    const data = input as Record<string, unknown>;\n\n    if (!data.thought || typeof data.thought !== 'string') {\n      throw new Error('Invalid thought: must be a string');\n    }\n    if (!data.thoughtNumber || typeof data.thoughtNumber !== 'number') {\n      throw new Error('Invalid thoughtNumber: must be a number');\n    }\n    if (!data.totalThoughts || typeof data.totalThoughts !== 'number') {\n      throw new Error('Invalid totalThoughts: must be a number');\n    }\n    if (typeof data.nextThoughtNeeded !== 'boolean') {\n      throw new Error('Invalid nextThoughtNeeded: must be a boolean');\n    }\n\n    return {\n      thought: data.thought,\n      thoughtNumber: data.thoughtNumber,\n      totalThoughts: data.totalThoughts,\n      nextThoughtNeeded: data.nextThoughtNeeded,\n      isRevision: data.isRevision as boolean | undefined,\n      revisesThought: data.revisesThought as number | undefined,\n      branchFromThought: data.branchFromThought as number | undefined,\n      branchId: data.branchId as string | undefined,\n      needsM\n... (content truncated)\n\n--- src/sequentialthinking/package.json (json) ---\n{\n  \"name\": \"@modelcontextprotocol/server-sequential-thinking\",\n  \"version\": \"0.6.2\",\n  \"description\": \"MCP server for sequential thinking and problem solving\",\n  \"license\": \"MIT\",\n  \"author\": \"Anthropic, PBC (https://anthropic.com)\",\n  \"homepage\": \"https://modelcontextprotocol.io\",\n  \"bugs\": \"https://github.com/modelcontextprotocol/servers/issues\",\n  \"type\": \"module\",\n  \"bin\": {\n    \"mcp-server-sequential-thinking\": \"dist/index.js\"\n  },\n  \"files\": [\n    \"dist\"\n  ],\n  \"scripts\": {\n    \"build\": \"tsc && shx chmod +x dist/*.js\",\n    \"prepare\": \"npm run build\",\n    \"watch\": \"tsc --watch\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"0.5.0\",\n    \"chalk\": \"^5.3.0\",\n    \"yargs\": \"^17.7.2\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^22\",\n    \"@types/yargs\": \"^17.0.32\",\n    \"shx\": \"^0.3.4\",\n    \"typescript\": \"^5.3.3\"\n  }\n}\n\n--- src/sequentialthinking/tsconfig.json (json) ---\n{\n  \"extends\": \"../../tsconfig.json\",\n  \"compilerOptions\": {\n    \"outDir\": \"./dist\",\n    \"rootDir\": \".\",\n    \"moduleResolution\": \"NodeNext\",\n    \"module\": \"NodeNext\"\n  },\n  \"include\": [\"./**/*.ts\"]\n}\n\n\n--- src/time/Dockerfile (unknown) ---\n# Use a Python image with uv pre-installed\nFROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS uv\n\n# Install the project into `/app`\nWORKDIR /app\n\n# Enable bytecode compilation\nENV UV_COMPILE_BYTECODE=1\n\n# Copy from the cache instead of linking since it's a mounted volume\nENV UV_LINK_MODE=copy\n\n# Install the project's dependencies using the lockfile and settings\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev --no-editable\n\n# Then, add the rest of the project source code and install it\n# Installing separately from its dependencies allows optimal layer caching\nADD . /app\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev --no-editable\n\nFROM python:3.12-slim-bookworm\n\nWORKDIR /app\n \nCOPY --from=uv /root/.local /root/.local\nCOPY --from=uv --chown=app:app /app/.venv /app/.venv\n\n# Place executables in the environment at the front of the path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# when running the container, add --db-path and a bind mount to the host's db file\nENTRYPOINT [\"mcp-server-time\"]\n\n\n--- src/time/README.md (md) ---\n# Time MCP Server\n\nA Model Context Protocol server that provides time and timezone conversion capabilities. This server enables LLMs to get current time information and perform timezone conversions using IANA timezone names, with automatic system timezone detection.\n\n### Available Tools\n\n- `get_current_time` - Get current time in a specific timezone or system timezone.\n  - Required arguments:\n    - `timezone` (string): IANA timezone name (e.g., 'America/New_York', 'Europe/London')\n\n- `convert_time` - Convert time between timezones.\n  - Required arguments:\n    - `source_timezone` (string): Source IANA timezone name\n    - `time` (string): Time in 24-hour format (HH:MM)\n    - `target_timezone` (string): Target IANA timezone name\n\n## Installation\n\n### Using uv (recommended)\n\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *mcp-server-time*.\n\n### Using PIP\n\nAlternatively you can install `mcp-server-time` via pip:\n\n```bash\npip install mcp-server-time\n```\n\nAfter installation, you can run it as a script using:\n\n```bash\npython -m mcp_server_time\n```\n\n## Configuration\n\n### Configure for Claude.app\n\nAdd to your Claude settings:\n\n<details>\n<summary>Using uvx</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"time\": {\n      \"command\": \"uvx\",\n      \"args\": [\"mcp-server-time\"]\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary>Using docker</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"time\": {\n      \"command\": \"docker\",\n      \"args\": [\"run\", \"-i\", \"--rm\", \"mcp/time\"]\n    }\n  }\n}\n```\n</details>\n\n<details>\n<summary>Using pip installation</summary>\n\n```json\n{\n  \"mcpServers\": {\n    \"time\": {\n      \"command\": \"python\",\n      \"args\": [\"-m\", \"mcp_server_time\"]\n    }\n  }\n}\n```\n</details>\n\n### Configure for Zed\n\nAdd to your Zed settings.json:\n\n<details>\n<summary>Using uvx</summary>\n\n```json\n\"context_servers\": [\n  \"mcp-server-time\": {\n    \"command\": \"uvx\",\n    \"args\": [\"mcp-server-time\"]\n  }\n],\n... (content truncated)\n\n--- src/time/pyproject.toml (toml) ---\n[project]\nname = \"mcp-server-time\"\nversion = \"0.6.2\"\ndescription = \"A Model Context Protocol server providing tools for time queries and timezone conversions for LLMs\"\nreadme = \"README.md\"\nrequires-python = \">=3.10\"\nauthors = [\n    { name = \"Mariusz 'maledorak' Korzekwa\", email = \"mariusz@korzekwa.dev\" },\n]\nkeywords = [\"time\", \"timezone\", \"mcp\", \"llm\"]\nlicense = { text = \"MIT\" }\nclassifiers = [\n    \"Development Status :: 4 - Beta\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.10\",\n]\ndependencies = [\n    \"mcp>=1.0.0\",\n    \"pydantic>=2.0.0\",\n    \"tzdata>=2024.2\",\n    \"tzlocal>=5.3.1\"\n]\n\n[project.scripts]\nmcp-server-time = \"mcp_server_time:main\"\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.uv]\ndev-dependencies = [\n    \"freezegun>=1.5.1\",\n    \"pyright>=1.1.389\",\n    \"pytest>=8.3.3\",\n    \"ruff>=0.8.1\",\n]\n\n\n--- src/time/src/mcp_server_time/__init__.py (py) ---\nfrom .server import serve\n\n\ndef main():\n    \"\"\"MCP Time Server - Time and timezone conversion functionality for MCP\"\"\"\n    import argparse\n    import asyncio\n\n    parser = argparse.ArgumentParser(\n        description=\"give a model the ability to handle time queries and timezone conversions\"\n    )\n    parser.add_argument(\"--local-timezone\", type=str, help=\"Override local timezone\")\n\n    args = parser.parse_args()\n    asyncio.run(serve(args.local_timezone))\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n--- src/time/src/mcp_server_time/__main__.py (py) ---\nfrom mcp_server_time import main\n\nmain()\n\n\n--- src/time/src/mcp_server_time/server.py (py) ---\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nimport json\nfrom typing import Sequence\n\nfrom zoneinfo import ZoneInfo\nfrom tzlocal import get_localzone_name  # ← returns \"Europe/Paris\", etc.\n\nfrom mcp.server import Server\nfrom mcp.server.stdio import stdio_server\nfrom mcp.types import Tool, TextContent, ImageContent, EmbeddedResource\nfrom mcp.shared.exceptions import McpError\n\nfrom pydantic import BaseModel\n\n\nclass TimeTools(str, Enum):\n    GET_CURRENT_TIME = \"get_current_time\"\n    CONVERT_TIME = \"convert_time\"\n\n\nclass TimeResult(BaseModel):\n    timezone: str\n    datetime: str\n    is_dst: bool\n\n\nclass TimeConversionResult(BaseModel):\n    source: TimeResult\n    target: TimeResult\n    time_difference: str\n\n\nclass TimeConversionInput(BaseModel):\n    source_tz: str\n    time: str\n    target_tz_list: list[str]\n\n\ndef get_local_tz(local_tz_override: str | None = None) -> ZoneInfo:\n    if local_tz_override:\n        return ZoneInfo(local_tz_override)\n\n    # Get local timezone from datetime.now()\n    local_tzname = get_localzone_name()\n    if local_tzname is not None:\n        return ZoneInfo(local_tzname)\n    raise McpError(\"Could not determine local timezone - tzinfo is None\")\n\n\ndef get_zoneinfo(timezone_name: str) -> ZoneInfo:\n    try:\n        return ZoneInfo(timezone_name)\n    except Exception as e:\n        raise McpError(f\"Invalid timezone: {str(e)}\")\n\n\nclass TimeServer:\n    def get_current_time(self, timezone_name: str) -> TimeResult:\n        \"\"\"Get current time in specified timezone\"\"\"\n        timezone = get_zoneinfo(timezone_name)\n        current_time = datetime.now(timezone)\n\n        return TimeResult(\n            timezone=timezone_name,\n            datetime=current_time.isoformat(timespec=\"seconds\"),\n            is_dst=bool(current_time.dst()),\n        )\n\n    def convert_time(\n        self, source_tz: str, time_str: str, target_tz: str\n    ) -> TimeConversionResult:\n        \"\"\"Convert time between timezones\"\"\"\n        source_timezone = get_zoneinfo(sou\n... (content truncated)\n\n--- src/time/test/time_server_test.py (py) ---\n\nfrom freezegun import freeze_time\nfrom mcp.shared.exceptions import McpError\nimport pytest\n\nfrom mcp_server_time.server import TimeServer\n\n\n@pytest.mark.parametrize(\n    \"test_time,timezone,expected\",\n    [\n        # UTC+1 non-DST\n        (\n            \"2024-01-01 12:00:00+00:00\",\n            \"Europe/Warsaw\",\n            {\n                \"timezone\": \"Europe/Warsaw\",\n                \"datetime\": \"2024-01-01T13:00:00+01:00\",\n                \"is_dst\": False,\n            },\n        ),\n        # UTC non-DST\n        (\n            \"2024-01-01 12:00:00+00:00\",\n            \"Europe/London\",\n            {\n                \"timezone\": \"Europe/London\",\n                \"datetime\": \"2024-01-01T12:00:00+00:00\",\n                \"is_dst\": False,\n            },\n        ),\n        # UTC-5 non-DST\n        (\n            \"2024-01-01 12:00:00-00:00\",\n            \"America/New_York\",\n            {\n                \"timezone\": \"America/New_York\",\n                \"datetime\": \"2024-01-01T07:00:00-05:00\",\n                \"is_dst\": False,\n            },\n        ),\n        # UTC+1 DST\n        (\n            \"2024-03-31 12:00:00+00:00\",\n            \"Europe/Warsaw\",\n            {\n                \"timezone\": \"Europe/Warsaw\",\n                \"datetime\": \"2024-03-31T14:00:00+02:00\",\n                \"is_dst\": True,\n            },\n        ),\n        # UTC DST\n        (\n            \"2024-03-31 12:00:00+00:00\",\n            \"Europe/London\",\n            {\n                \"timezone\": \"Europe/London\",\n                \"datetime\": \"2024-03-31T13:00:00+01:00\",\n                \"is_dst\": True,\n            },\n        ),\n        # UTC-5 DST\n        (\n            \"2024-03-31 12:00:00-00:00\",\n            \"America/New_York\",\n            {\n                \"timezone\": \"America/New_York\",\n                \"datetime\": \"2024-03-31T08:00:00-04:00\",\n                \"is_dst\": True,\n            },\n        ),\n    ],\n)\ndef test_get_current_time(test_time, timezone, expected):\n    with freeze_time(test_time):\n        time_server = Tim\n... (content truncated)\n\n--- tsconfig.json (json) ---\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"Node16\",\n    \"moduleResolution\": \"Node16\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\"]\n}\n\n\n\n**ORGANIZATION-WIDE CONTEXT:**\nThis organization has 4 repositories total.\n\n**Organization Patterns:**\n- Common Languages: \n- Common Frameworks: \n- File Extensions Used: .gitattributes (1 files), .md (22 files), .yml (6 files), .gitignore (6 files), .json (29 files), .no_ext (13 files), .py (40 files), .ts (53 files), .toml (4 files), .example (2 files)\n\n**Other Repositories in Organization:**\n- jayasaisrikar-flockshop: ## FlockShop Repository Architecture Analysis\n\nBased on the provided files, FlockShop is a web appli...\n- jayasaisrikar-bi_dashboard: ## Wayne Enterprises Business Intelligence Dashboard: Repository Analysis\n\nBased on the provided fil...\n- jayasaisrikar-portfolio_app: ## Repository Architecture Analysis\n\nThis Django-based portfolio website uses a modular architecture...\n\n**Architecture Analysis:**\n## Analysis of the Provided Model Context Protocol (MCP) Server Repository\n\nThis repository contains multiple MCP server implementations, each residing in its own subdirectory within the `src` folder.  The structure suggests a modular design allowing for different server types (e.g., filesystem, Git, everything) and transport mechanisms (e.g., stdio, SSE).\n\n**1. Detailed Architecture Summary:**\n\nThe repository follows a microservice-like architecture.  Each server type (`everything`, `fetch`, `filesystem`, `git`) is a self-contained unit with its own `package.json`, `Dockerfile`, and potentially other configuration files. The `package.json` at the root level manages these individual servers as workspaces.  A `release.py` script handles the release process.  The `.github` directory contains GitHub Actions workflows for Python, release management, and TypeScript projects.  A significant portion is dedicated to the \"everything\" server, which appears to be a comprehensive demonstration server, incorporating various features and functionalities.\n\n\n**2. Key Components and their Relationships:**\n\n* **Root `package.json`:** Manages the entire project as a workspace, defining dependencies between the different server modules (`@modelcontextprotocol/server-*`).\n* **`src/everything`:** A comprehensive demonstration server implementing different transport mechanisms (stdio, SSE, streamable HTTP). It includes `everything.ts`, `index.ts`, `stdio.ts`, `sse.ts`, and `streamableHttp.ts` files handling various functionalities.  `CLAUDE.md` provides development guidelines.\n* **`src/fetch`:** A server likely focused on fetching data,  indicated by `__main__.py`, `server.py`, and `pyproject.toml`.\n* **`src/filesystem`:** A server that interacts with the file system, as evident from file names like `path-utils.ts` and `roots-utils.ts`.\n* **`src/git`:** A server presumably interacting with Git repositories.\n* **`scripts/release.py`:** A Python script presumably for automating the release process.\n* **`.github/workflows/*`:  GitHub Actions workflows** for automated build, testing, and release processes for Python and TypeScript projects.\n\n\n**3. Data Flow Patterns and API Structure:**\n\nThe `src/everything/index.ts` file reveals a command-line interface accepting a script name (`stdio`, `sse`, `streamableHttp`) to select the server implementation.  Each server implementation (`stdio.ts`, `sse.ts`, `streamableHttp.ts`) likely defines its own API for handling requests and responses. The `CLAUDE.md` file suggests using Zod for input validation.  The data flow depends on the specific server implementation. The `everything` server handles resources and progress notifications based on the provided documentation in `instructions.md`.\n\n\n**4. Integration Points and Dependencies:**\n\n* **Internal Dependencies:** The root `package.json` shows dependencies between the different server modules (e.g., `@modelcontextprotocol/server-everything`).\n* **External Dependencies:**  The full extent of external dependencies is not explicitly shown, but inferred from the presence of `package-lock.json` and the `npm install` command in the `Dockerfile`. The `everything` server likely uses Node.js and TypeScript. The `fetch` and `git` servers use Python.\n* **Infrastructure Dependencies:** Docker is used for building and running the servers.\n\n\n**5. Specific Feature Addition Recommendations:**\n\nBased on the provided files, here are some recommendations:\n\n* **Improved Logging in `src/everything`:**  Enhance the logging mechanism in `src/everything` to provide more detailed information about requests, responses, and errors. Add logging levels (DEBUG, INFO, WARN, ERROR) to facilitate debugging and monitoring. (Files: `src/everything/stdio.ts`, `src/everything/sse.ts`, `src/everything/streamableHttp.ts`)\n* **Enhanced Error Handling in `src/everything`:** Implement more robust error handling and reporting mechanisms to provide users with more informative error messages.  Consider using a standardized error format. (Files: `src/everything/stdio.ts`, `src/everything/sse.ts`, `src/everything/streamableHttp.ts`)\n* **Metrics and Monitoring:** Add code to collect metrics (e.g., request latency, throughput, error rates) and integrate with a monitoring system. This requires adding relevant libraries and configuration. (Files:  `src/everything/index.ts`, potentially others)\n* **Testing Improvements:** Add more comprehensive unit and integration tests to ensure the stability and correctness of the servers. Implement these tests in the relevant server directories. (Files: `src/filesystem/__tests__/*.ts`, add similar tests to other directories)\n* **Documentation Enhancements:**  Expand the documentation in `CLAUDE.md` and `instructions.md` to clarify API specifications, request/response formats, and configuration options. Add API documentation using tools like Swagger or OpenAPI.  (Files: `src/everything/CLAUDE.md`, `src/everything/instructions.md`, and potentially others).\n\n\nThese recommendations aim to improve the robustness, maintainability, and usability of the MCP server implementations.  The specific implementation details will depend on the chosen technologies and design patterns.\n\n\n**System Diagram:**\n```mermaid\ngraph TD\ngroup_gitattributes[GITATTRIBUTES Files]\nfile_1[.gitattributes]\ngroup_gitattributes --> file_1\nclick file_1 \".gitattributes\"\ngroup_md[MD Files]\nfile_2[pull_request_template.md]\ngroup_md --> file_2\nclick file_2 \".github/pull_request_template.md\"\nfile_3[CODE_OF_CONDUCT.md]\ngroup_md --> file_3\nclick file_3 \"CODE_OF_CONDUCT.md\"\ngroup_yml[YML Files]\nfile_4[python.yml]\ngroup_yml --> file_4\nclick file_4 \".github/workflows/python.yml\"\nfile_5[release.yml]\ngroup_yml --> file_5\nclick file_5 \".github/workflows/release.yml\"\ngroup_gitignore[GITIGNORE Files]\nfile_6[.gitignore]\ngroup_gitignore --> file_6\nclick file_6 \".gitignore\"\nfile_7[.gitignore]\ngroup_gitignore --> file_7\nclick file_7 \"src/git/.gitignore\"\ngroup_json[JSON Files]\nfile_8[settings.json]\ngroup_json --> file_8\nclick file_8 \".vscode/settings.json\"\nfile_9[package-lock.json]\ngroup_json --> file_9\nclick file_9 \"package-lock.json\"\ngroup_unknown[UNKNOWN Files]\nfile_10[LICENSE]\ngroup_unknown --> file_10\nclick file_10 \"LICENSE\"\nfile_11[Dockerfile]\ngroup_unknown --> file_11\nclick file_11 \"src/everything/Dockerfile\"\ngroup_py[PY Files]\nfile_12[release.py]\ngroup_py --> file_12\nclick file_12 \"scripts/release.py\"\nfile_13[__init__.py]\ngroup_py --> file_13\nclick file_13 \"src/fetch/src/mcp_server_fetch/__init__.py\"\ngroup_ts[TS Files]\nfile_14[everything.ts]\ngroup_ts --> file_14\nclick file_14 \"src/everything/everything.ts\"\nfile_15[index.ts]\ngroup_ts --> file_15\nclick file_15 \"src/everything/index.ts\"\ngroup_toml[TOML Files]\nfile_16[pyproject.toml]\ngroup_toml --> file_16\nclick file_16 \"src/fetch/pyproject.toml\"\nfile_17[pyproject.toml]\ngroup_toml --> file_17\nclick file_17 \"src/git/pyproject.toml\"\ngroup_gitattributes --> group_md\ngroup_md --> group_yml\ngroup_yml --> group_gitignore\ngroup_gitignore --> group_json\ngroup_json --> group_unknown\ngroup_unknown --> group_py\ngroup_py --> group_ts\ngroup_ts --> group_toml\n```\n\nIMPORTANT: Use the relevant conversation history above to maintain context and avoid repeating information. Build upon previous discussions and reference earlier conversations when relevant.\n\nYou now have access to the COMPLETE codebase structure and file contents PLUS context from 4 other repositories in this organization PLUS relevant conversation history.\n\nWhen answering:\n1. **Reference previous conversations** and build upon them\n2. Use patterns from other repos in the organization\n3. Suggest consistency with the org's common tech stack\n4. Reference similar implementations from other repos when relevant\n5. Consider the organization's architectural patterns\n\nWhen suggesting where to add new features:\n1. Follow patterns used across the organization\n2. Identify the exact files that would need to be modified\n3. Specify the exact locations within those files\n4. Provide code examples based on the existing patterns in THIS codebase AND organization patterns\n5. Consider the existing architecture and follow the same patterns used across all repos\n6. **Build upon previous suggestions** and maintain conversation continuity\n\nConsider the conversation history when answering to maintain context and avoid repeating information already provided.\n",
  "response": "Building a similar MCP server within the `flockshop` repository requires careful consideration of FlockShop's existing architecture (which we only have a high-level description of) and the `modelcontextprotocol-servers` repository's structure.  Since we lack detailed knowledge of FlockShop's internal workings, we can only offer a high-level approach and recommendations based on the provided information.\n\nAssuming FlockShop is a web application, integrating an MCP server would likely involve adding a new microservice-like component, mirroring the structure of the `modelcontextprotocol-servers` repository.  This approach promotes modularity and avoids tight coupling.\n\n**Proposed Structure (within `flockshop`):**\n\n1. **Create a new directory:**  Add a directory, perhaps `src/mcp_server`, to house the new server implementation.\n\n2. **Choose a language and framework:** Based on the organization's existing repositories, Python seems to be a prevalent choice.  If consistency is desired, a Python-based server would align well with the existing `fetch`, `git`, and `time` servers in `modelcontextprotocol-servers`.\n\n3. **Server Implementation:**  Create the necessary files for the server implementation.  This will depend on the server's intended function within FlockShop. Let's assume, for example, that this server will manage product data, similar to the \"filesystem\" server's role.\n\n   * **`src/mcp_server/server.py`:**  The main server logic, including handling MCP requests, interacting with FlockShop's product database (assuming it exists), and responding appropriately.  This should use the MCP Python SDK.\n\n   * **`src/mcp_server/tools.py`:**  A module defining the specific tools exposed by this server. This could include tools like `get_product_details`, `list_products`, `update_product_inventory`, etc. These tools would directly interact with FlockShop's database or API.\n\n   * **`src/mcp_server/main.py`:** A simple entry point to run the server, setting logging levels as needed (mirroring the verbose option in `src/git/src/mcp_server_git/__init__.py`).\n\n   * **`src/mcp_server/pyproject.toml`:**  The project metadata (dependencies, etc.), similar to the `pyproject.toml` files in `modelcontextprotocol-servers`.  Ensure `mcp` and the appropriate database connector library are included as dependencies.\n\n4. **Integration with FlockShop:** The server needs a mechanism to connect to FlockShop's database or API to access and manipulate product information. This may require adjustments to FlockShop's existing architecture or the creation of an intermediary API layer.\n\n5. **Testing:**  Implement unit tests and potentially integration tests, following the patterns observed in the `modelcontextprotocol-servers` repository (e.g., `test_server.py` in the `src/git` directory).\n\n\n**Code Example (Illustrative – `src/mcp_server/tools.py`):**\n\n```python\nfrom mcp.types import Tool, TextContent\nfrom flockshop.models import Product # Assuming a Product model exists in FlockShop\n\ndef get_product_details(product_id: int) -> TextContent:\n    \"\"\"Retrieves details of a specific product.\"\"\"\n    try:\n        product = Product.objects.get(pk=product_id) # Replace with actual database query\n        details = f\"Product ID: {product.id}\\nName: {product.name}\\nPrice: {product.price}\\nDescription: {product.description}\"\n        return TextContent(content=details)\n    except Product.DoesNotExist:\n        return TextContent(content=f\"Product with ID {product_id} not found.\")\n\n# Define other tools similarly...\n\nTOOLS = [\n    Tool(\n        name=\"get_product_details\",\n        description=\"Retrieves details for a given product ID.\",\n        input_schema=...,  # Add Pydantic schema for input validation\n        output_schema=...,  # Add Pydantic schema for output validation\n        function=get_product_details,\n    ),\n    # ... other tools\n]\n\n```\n\n**Addressing potential challenges:**\n\n* **Database Integration:**  This is highly dependent on FlockShop's database technology and structure. Thorough knowledge of FlockShop's database is necessary to implement appropriate data access methods.\n* **API Design:**  The API exposed by the MCP server must align with FlockShop's needs and security considerations. Careful planning of the tools and their input/output schemas is crucial.\n\nThis detailed response expands upon the previous analysis by providing a practical, structured approach to building an MCP server within the FlockShop repository, emphasizing consistency with the organization's existing patterns and code style. Remember to adapt these suggestions based on the specifics of the FlockShop application.\n",
  "model": "Gemini",
  "timestamp": "2025-07-18T10:44:21.357099"
}